{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inesbenhamza/Desktop/untitled folder 2/hw1DL/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "import numpy as np\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf\n",
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# directory check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/inesbenhamza/Downloads/deeplearningproject/notebooks\n",
      "Method 1: Found project root (from notebooks dir): /Users/inesbenhamza/Downloads/deeplearningproject\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "project_root = None\n",
    "\n",
    "if os.path.basename(current_dir) == 'notebooks':\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "    print(f\"Method 1: Found project root (from notebooks dir): {project_root}\")\n",
    "else:\n",
    "\n",
    "    if os.path.exists(os.path.join(current_dir, 'helpers')):\n",
    "        project_root = current_dir\n",
    "        print(f\"Method 2: Found project root (helpers in current dir): {project_root}\")\n",
    "    elif os.path.exists(os.path.join(os.path.dirname(current_dir), 'helpers')):\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "        print(f\"Method 3: Found project root (helpers in parent dir): {project_root}\")\n",
    "    else:\n",
    "        \n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "        if os.path.exists(os.path.join(parent_dir, 'helpers')):\n",
    "            project_root = parent_dir\n",
    "            print(f\"Method 4: Found project root (going up one level): {project_root}\")\n",
    "        else:\n",
    "            known_project_root = \"/Users/inesbenhamza/Downloads/deeplearningproject\"\n",
    "            if os.path.exists(os.path.join(known_project_root, 'helpers')):\n",
    "                project_root = known_project_root\n",
    "                print(f\"Method 5: Using known absolute path: {project_root}\")\n",
    "\n",
    "if project_root and os.path.exists(os.path.join(project_root, 'helpers')):\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers\n",
    "#!pip install torch\n",
    "#!pip install numpy\n",
    "#!pip install scipy\n",
    "#!pip install pandas\n",
    "#!pip install pyyaml\n",
    "#!pip install streamlit\n",
    "#!pip install pymupdf\n",
    "#!pip install pdfplumber\n",
    "#!pip install anthropic\n",
    "#!pip install openai\n",
    "#!pip install google-generativeai\n",
    "#!pip install watchdog\n",
    "#!pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U sentence-transformers\n",
    "#!pip install pypdf\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sentence_transformers import SentenceTransformer\n",
    "#from SkillsEmbeddings import SkillEmbeddingModel, save_skills_emb\n",
    "\n",
    "#model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "#skill_model = SkillEmbeddingModel(model)\n",
    "\n",
    "#save_skills_emb(\n",
    "    #input_csv=\"skills/skillscleaned.csv\",\n",
    "    #output_npz=\"skills/skills_encoded.npz\",\n",
    "    #model=skill_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting pdf text for encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "def extract_text(filename: str):\n",
    "    reader = PdfReader(filename)\n",
    "    complete_text = \"\"\n",
    "    \n",
    "    for page in reader.pages:\n",
    "        complete_text += f\"\\n{page.extract_text()}\"\n",
    "    return complete_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HCK_HEC_LANG.csv', '.DS_Store', 'HCK_HEC_XP.csv', 'HCK_HEC_SKILLS.csv', 'HCK_HEC_USER.csv', 'HCK_HEC_STAFFING.csv', 'raw']\n"
     ]
    }
   ],
   "source": [
    "if 'project_root' not in globals():\n",
    "    current_dir = os.getcwd()\n",
    "    if os.path.basename(current_dir) == 'notebooks':\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading all file at the same time not so useful "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning the lang dataset \n",
    "it contains the user IDs, the langauge and the skill level\n",
    "there are some NAs values that we replace by -1 (need to check why we did that in the first place)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = pd.read_csv(\"/Users/inesbenhamza/Downloads/deeplearningproject/data/HCK_HEC_LANG.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USER_ID LANGUAGE_SKILL_DSC  LANGUAGE_SKILL_LVL\n",
      "38   2433141             French               100.0\n",
      "102  2433141            English               100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csvfile[csvfile['USER_ID']==2433141])\n",
    "csvfile['LANGUAGE_SKILL_LVL'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile['LANGUAGE_SKILL_LVL'] = csvfile['LANGUAGE_SKILL_LVL'].fillna(-1) # to handle missing values we fill them with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile['LANGUAGE_SKILL_LVL'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USER_ID LANGUAGE_SKILL_DSC  LANGUAGE_SKILL_LVL\n",
      "0  2432194            English               100.0\n",
      "1  2432194             French               100.0\n",
      "2  2433083            English                80.0\n",
      "3  2433083             French               100.0\n",
      "4  2433092            English                80.0\n",
      "5  2433092             French               100.0\n",
      "6  2433099            English                80.0\n",
      "7  2433099             French               100.0\n",
      "8  2433109            English                80.0\n",
      "9  2433109             French               100.0\n"
     ]
    }
   ],
   "source": [
    "df_filtered = csvfile.loc[csvfile.groupby(['USER_ID', 'LANGUAGE_SKILL_DSC'])['LANGUAGE_SKILL_LVL'].idxmax()]\n",
    " \n",
    "\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "print(df_filtered.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LANGUAGE_SKILL_DSC</th>\n",
       "      <th>LANGUAGE_SKILL_LVL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2664664</td>\n",
       "      <td>English</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2664664</td>\n",
       "      <td>French</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LANGUAGE_SKILL_DSC  LANGUAGE_SKILL_LVL\n",
       "170  2664664            English                -1.0\n",
       "171  2664664             French                -1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[df_filtered['USER_ID'] == 2664664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print (df_filtered.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# storing lang clean into a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"langcleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a consultant_profile_df by merging all csv ( should we creat col skills 1, skills 2 etc ? or skilss : skills1,skills2 etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gettign workign directory \n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USER_ID LAST_NAME FIRST_NAME  ANNEES_XP\n",
      "0  2843838     Ramos      David        1.0\n",
      "1  2479537     Small       Carl        2.5\n",
      "2  2533337     Evans     Carmen        2.0\n",
      "3  2446382   Pittman     Brandi        2.5\n",
      "4  2433124    Thomas      Julie        2.5\n"
     ]
    }
   ],
   "source": [
    "expyears  = pd.read_csv(\"/Users/inesbenhamza/Downloads/deeplearningproject/data/HCK_HEC_USER.csv\")\n",
    "expyears['USER_ID'].nunique()\n",
    "\n",
    "print(expyears.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USer an dtheir name + experience in year is clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [USER_ID, LAST_NAME, FIRST_NAME, ANNEES_XP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(expyears.duplicated().sum())\n",
    "print(expyears[expyears.duplicated(subset=['USER_ID'], keep=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>SKILLS_DSC</th>\n",
       "      <th>DOMAIN_DSC</th>\n",
       "      <th>LEVEL_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2433083</td>\n",
       "      <td>DBT</td>\n",
       "      <td>Data Integration</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Analytics Platform System (SSAS)</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Azure Data Factory</td>\n",
       "      <td>Data Integration</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Azure Data Lake Store</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Azure SQL Database</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2978961</td>\n",
       "      <td>Snowflake Data Cloud</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2978961</td>\n",
       "      <td>Tableau Desktop and Online</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>3072774</td>\n",
       "      <td>Python</td>\n",
       "      <td>Programming Language</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>3072774</td>\n",
       "      <td>R</td>\n",
       "      <td>Programming Language</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>3072774</td>\n",
       "      <td>SQL</td>\n",
       "      <td>Programming Language</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID                                  SKILLS_DSC  \\\n",
       "0    2433083                                         DBT   \n",
       "1    2433083  Microsoft Analytics Platform System (SSAS)   \n",
       "2    2433083                Microsoft Azure Data Factory   \n",
       "3    2433083             Microsoft Azure Data Lake Store   \n",
       "4    2433083                Microsoft Azure SQL Database   \n",
       "..       ...                                         ...   \n",
       "979  2978961                        Snowflake Data Cloud   \n",
       "980  2978961                  Tableau Desktop and Online   \n",
       "981  3072774                                      Python   \n",
       "982  3072774                                           R   \n",
       "983  3072774                                         SQL   \n",
       "\n",
       "               DOMAIN_DSC  LEVEL_VAL  \n",
       "0        Data Integration       80.0  \n",
       "1         Data Management       80.0  \n",
       "2        Data Integration      100.0  \n",
       "3         Data Management       90.0  \n",
       "4         Data Management       90.0  \n",
       "..                    ...        ...  \n",
       "979       Data Management        0.0  \n",
       "980        Data Analytics        0.0  \n",
       "981  Programming Language       40.0  \n",
       "982  Programming Language       40.0  \n",
       "983  Programming Language       50.0  \n",
       "\n",
       "[984 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skillsclean = pd.read_csv(\"/Users/inesbenhamza/Downloads/deeplearningproject/data/raw/skillscleaned.csv\")\n",
    "\n",
    "skillsclean\n",
    "#print(print(skillsclean[skillsclean.duplicated(subset=['USER_ID'], keep=True)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Integration', 'Data Management', 'Agile Delivery',\n",
       "       'Financial Close', 'Data Analytics', 'Programming Language',\n",
       "       'Data Platform', 'Data Governance', 'Data Science',\n",
       "       'Financial Planning and Analysis'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skillsclean['DOMAIN_DSC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skills_df = skillsclean  \n",
    "\n",
    "\n",
    "pivoted_df = skills_df.pivot_table(\n",
    "    index='USER_ID',\n",
    "    columns='DOMAIN_DSC',\n",
    "    values='LEVEL_VAL',\n",
    "    aggfunc=lambda x: dict(zip(skills_df.loc[x.index, 'SKILLS_DSC'], x))\n",
    ")\n",
    "\n",
    "\n",
    "pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "\n",
    "pivoted_df\n",
    "\n",
    "pivoted_df.to_csv(\"skills_pivoted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMAIN_DSC  USER_ID                                     Agile Delivery  \\\n",
      "0           2433083                                                NaN   \n",
      "1           2433092  {'Atlassian JIRA Software': 100.0, 'Microsoft ...   \n",
      "2           2433099  {'Atlassian JIRA Software': 80.0, 'Microsoft A...   \n",
      "3           2433109  {'Atlassian JIRA Software': 100.0, 'Microsoft ...   \n",
      "4           2433111                                                NaN   \n",
      "\n",
      "DOMAIN_DSC                                     Data Analytics Data Governance  \\\n",
      "0                                                         NaN             NaN   \n",
      "1                                                         NaN             NaN   \n",
      "2                            {'SAP BusinessObjects BI': 20.0}             NaN   \n",
      "3                                                         NaN             NaN   \n",
      "4           {'Microsoft Power BI': 80.0, 'Tableau Desktop ...             NaN   \n",
      "\n",
      "DOMAIN_DSC                                   Data Integration  \\\n",
      "0           {'DBT': 80.0, 'Microsoft Azure Data Factory': ...   \n",
      "1                                                         NaN   \n",
      "2                                                         NaN   \n",
      "3           {'Informatica PowerCenter': 100.0, 'Matillion ...   \n",
      "4                                                         NaN   \n",
      "\n",
      "DOMAIN_DSC                                    Data Management Data Platform  \\\n",
      "0           {'Microsoft Analytics Platform System (SSAS)':...           NaN   \n",
      "1                                                         NaN           NaN   \n",
      "2           {'SAP BW': 90.0, 'SAP BW/4HANA': 70.0, 'SAP HA...           NaN   \n",
      "3           {'Google BigQuery': 100.0, 'IBM Db2': 100.0, '...           NaN   \n",
      "4           {'Microsoft SQL Server': 80.0, 'Snowflake Data...           NaN   \n",
      "\n",
      "DOMAIN_DSC Data Science                                    Financial Close  \\\n",
      "0                   NaN                                                NaN   \n",
      "1                   NaN                                                NaN   \n",
      "2                   NaN  {'SAP Business Planning and Consolidation (SAP...   \n",
      "3                   NaN                                                NaN   \n",
      "4                   NaN                                                NaN   \n",
      "\n",
      "DOMAIN_DSC Financial Planning and Analysis  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      NaN   \n",
      "4                                      NaN   \n",
      "\n",
      "DOMAIN_DSC                               Programming Language  \n",
      "0                                                         NaN  \n",
      "1                                                         NaN  \n",
      "2                                                         NaN  \n",
      "3           {'DAX': 100.0, 'MDX': 100.0, 'SQL': 100.0, 'T-...  \n",
      "4                                 {'DAX': 70.0, 'SQL': 100.0}  \n"
     ]
    }
   ],
   "source": [
    "print(pivoted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging\n",
    "with availibility \n",
    "expereince \n",
    "mission \n",
    "lang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['USER_ID', 'Agile Delivery', 'Data Analytics', 'Data Governance',\n",
      "       'Data Integration', 'Data Management', 'Data Platform', 'Data Science',\n",
      "       'Financial Close', 'Financial Planning and Analysis',\n",
      "       'Programming Language'],\n",
      "      dtype='object', name='DOMAIN_DSC')\n"
     ]
    }
   ],
   "source": [
    "# checking the col \n",
    "pivoted_df\n",
    "print(pivoted_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fulldf = expyears.merge(pivoted_df, on=\"USER_ID\", how=\"left\")\n",
    "fulldf['USER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df with user id, experience so ( USER) and SKILLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>Data Science</th>\n",
       "      <th>Financial Close</th>\n",
       "      <th>Financial Planning and Analysis</th>\n",
       "      <th>Programming Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Java': 70.0, 'Javascript': 20.0, 'PL/SQL': 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Hyperion Financial Management (HFM)':...</td>\n",
       "      <td>{'Applied OLAP Dodeca': 80.0, 'Oracle Cloud EP...</td>\n",
       "      <td>{'Java': 60.0, 'VBA': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Anaconda Enterprise': 0.0, 'Matlab': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Cognos TM1': 10.0}</td>\n",
       "      <td>{'DAX': 20.0, 'Java': 20.0, 'Python': 40.0, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Java': 40.0, 'Python': 60.0, 'R': 40.0, 'SQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'CCH Tagetik CPM Conso': 60.0, 'Oracle Hyperi...</td>\n",
       "      <td>{'CCH Tagetik CPM Planning': 80.0, 'Oracle Hyp...</td>\n",
       "      <td>{'Java': 50.0, 'Python': 40.0, 'R': 40.0, 'SQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Java': 30.0, 'Python': 70.0, 'SQL': 80.0, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                    Data Science  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2    {'Anaconda Enterprise': 0.0, 'Matlab': 0.0}   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "..                                           ...   \n",
       "114                                          NaN   \n",
       "115                                          NaN   \n",
       "116                                          NaN   \n",
       "117                                          NaN   \n",
       "118                                          NaN   \n",
       "\n",
       "                                       Financial Close  \\\n",
       "0                                                  NaN   \n",
       "1    {'Oracle Hyperion Financial Management (HFM)':...   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'CCH Tagetik CPM Conso': 60.0, 'Oracle Hyperi...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                       Financial Planning and Analysis  \\\n",
       "0                                                  NaN   \n",
       "1    {'Applied OLAP Dodeca': 80.0, 'Oracle Cloud EP...   \n",
       "2                             {'IBM Cognos TM1': 10.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'CCH Tagetik CPM Planning': 80.0, 'Oracle Hyp...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                  Programming Language  \n",
       "0    {'Java': 70.0, 'Javascript': 20.0, 'PL/SQL': 5...  \n",
       "1                         {'Java': 60.0, 'VBA': 100.0}  \n",
       "2    {'DAX': 20.0, 'Java': 20.0, 'Python': 40.0, 'S...  \n",
       "3    {'Java': 40.0, 'Python': 60.0, 'R': 40.0, 'SQL...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "114                                                NaN  \n",
       "115  {'Java': 50.0, 'Python': 40.0, 'R': 40.0, 'SQL...  \n",
       "116                                                NaN  \n",
       "117  {'Java': 30.0, 'Python': 70.0, 'SQL': 80.0, 'S...  \n",
       "118                                                NaN  \n",
       "\n",
       "[119 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "availibility= pd.read_csv('/Users/inesbenhamza/Downloads/deeplearningproject/data/HCK_HEC_STAFFING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = fulldf.merge(availibility, on=\"USER_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_3</th>\n",
       "      <th>MONTH_4</th>\n",
       "      <th>MONTH_5</th>\n",
       "      <th>MONTH_6</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  ... MONTH_3 MONTH_4  \\\n",
       "0                                                  NaN  ...     100     100   \n",
       "1                                                  NaN  ...     100     100   \n",
       "2                                                  NaN  ...      25      25   \n",
       "3                                                  NaN  ...      25      25   \n",
       "4                                                  NaN  ...      25      25   \n",
       "..                                                 ...  ...     ...     ...   \n",
       "114                                                NaN  ...      25      25   \n",
       "115                                                NaN  ...       0       0   \n",
       "116                                                NaN  ...       0      25   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...  ...      25      25   \n",
       "118                                                NaN  ...      50      50   \n",
       "\n",
       "    MONTH_5 MONTH_6  MONTH_7  MONTH_8  MONTH_9  MONTH_10  MONTH_11  MONTH_12  \n",
       "0       100     100      100      100      100       100       100       100  \n",
       "1       100     100      100      100      100       100       100       100  \n",
       "2        25      25       25       25       25        25        25        25  \n",
       "3        25      25       25       25       50        25        25        25  \n",
       "4        25      25       50       25       25        25        25        25  \n",
       "..      ...     ...      ...      ...      ...       ...       ...       ...  \n",
       "114      25      25       25       25       25        25        25        25  \n",
       "115       0       0        0        0        0         0         0         0  \n",
       "116       0       0        0        0        0         0         0         0  \n",
       "117      25      25       25       50       25        25        25        25  \n",
       "118      50      25       50       50       50        50        50        50  \n",
       "\n",
       "[119 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for lang and mission multiple col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/wz4hfzq14nggvhjg7kkdsts80000gn/T/ipykernel_50696/174774832.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lang_profiles = langskills.groupby(\"USER_ID\").apply(\n"
     ]
    }
   ],
   "source": [
    "langskills = pd.read_csv ('/Users/inesbenhamza/Downloads/deeplearningproject/data/raw/langcleaned.csv')\n",
    "\n",
    "lang_profiles = langskills.groupby(\"USER_ID\").apply(\n",
    "    lambda x: dict(zip(x[\"LANGUAGE_SKILL_DSC\"], x[\"LANGUAGE_SKILL_LVL\"]))\n",
    ").reset_index(name=\"LANGUAGE_PROFILE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_4</th>\n",
       "      <th>MONTH_5</th>\n",
       "      <th>MONTH_6</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "      <th>LANGUAGE_PROFILE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 90.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 50.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 60.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 80.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 80.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 70.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'English': 80.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  ... MONTH_4 MONTH_5  \\\n",
       "0                                                  NaN  ...     100     100   \n",
       "1                                                  NaN  ...     100     100   \n",
       "2                                                  NaN  ...      25      25   \n",
       "3                                                  NaN  ...      25      25   \n",
       "4                                                  NaN  ...      25      25   \n",
       "..                                                 ...  ...     ...     ...   \n",
       "114                                                NaN  ...      25      25   \n",
       "115                                                NaN  ...       0       0   \n",
       "116                                                NaN  ...      25       0   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...  ...      25      25   \n",
       "118                                                NaN  ...      50      50   \n",
       "\n",
       "    MONTH_6 MONTH_7  MONTH_8  MONTH_9  MONTH_10  MONTH_11  MONTH_12  \\\n",
       "0       100     100      100      100       100       100       100   \n",
       "1       100     100      100      100       100       100       100   \n",
       "2        25      25       25       25        25        25        25   \n",
       "3        25      25       25       50        25        25        25   \n",
       "4        25      50       25       25        25        25        25   \n",
       "..      ...     ...      ...      ...       ...       ...       ...   \n",
       "114      25      25       25       25        25        25        25   \n",
       "115       0       0        0        0         0         0         0   \n",
       "116       0       0        0        0         0         0         0   \n",
       "117      25      25       50       25        25        25        25   \n",
       "118      25      50       50       50        50        50        50   \n",
       "\n",
       "                        LANGUAGE_PROFILE  \n",
       "0    {'English': 100.0, 'French': 100.0}  \n",
       "1     {'English': 90.0, 'French': 100.0}  \n",
       "2     {'English': 50.0, 'French': 100.0}  \n",
       "3     {'English': 60.0, 'French': 100.0}  \n",
       "4    {'English': 100.0, 'French': 100.0}  \n",
       "..                                   ...  \n",
       "114   {'English': 100.0, 'French': 80.0}  \n",
       "115  {'English': 100.0, 'French': 100.0}  \n",
       "116   {'English': 80.0, 'French': 100.0}  \n",
       "117   {'English': 70.0, 'French': 100.0}  \n",
       "118                    {'English': 80.0}  \n",
       "\n",
       "[119 rows x 27 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf = fulldf.merge(lang_profiles, on=\"USER_ID\", how=\"left\")\n",
    "\n",
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission = pd.read_csv('/Users/inesbenhamza/Downloads/deeplearningproject/data/HCK_HEC_XP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we gorup mission by user so that it become \n",
    "USER_ID\tMISSIONS_LIST\n",
    "2843838\t[mission1, mission2, mission3, …]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      USER_ID                                      MISSIONS_LIST  \\\n",
      "0     2432194  [Analyse de la situation actuelle et définitio...   \n",
      "1     2433083  [Exhaustive data analysis, Translation of the ...   \n",
      "2     2433092  [Gestion du budget., Planification de l'échéan...   \n",
      "3     2433099  [Faire le suivi des activités de configuration...   \n",
      "4     2433109  [Understanding of customer requirements, Analy...   \n",
      "..        ...                                                ...   \n",
      "119  29209385  [Coordinated clinical documentation workflows ...   \n",
      "120  29209386  [Oversaw scheduling, planning, and logistics f...   \n",
      "121  29209387  [Assisted regional public health authorities i...   \n",
      "122  29209388  [Conducted internal audits on patient safety p...   \n",
      "123  29209389  [Supported principal investigators in preparin...   \n",
      "\n",
      "                                         MISSIONS_TEXT  \n",
      "0    Analyse de la situation actuelle et définition...  \n",
      "1    Exhaustive data analysis Translation of the bu...  \n",
      "2    Gestion du budget. Planification de l'échéanci...  \n",
      "3    Faire le suivi des activités de configuration ...  \n",
      "4    Understanding of customer requirements Analysi...  \n",
      "..                                                 ...  \n",
      "119  Coordinated clinical documentation workflows a...  \n",
      "120  Oversaw scheduling, planning, and logistics fo...  \n",
      "121  Assisted regional public health authorities in...  \n",
      "122  Conducted internal audits on patient safety pr...  \n",
      "123  Supported principal investigators in preparing...  \n",
      "\n",
      "[124 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missions_grouped = mission.groupby(\"USER_ID\")[\"MISSION_DSC\"].apply(list).reset_index(name=\"MISSIONS_LIST\")\n",
    "\n",
    "\n",
    "missions_grouped[\"MISSIONS_TEXT\"] = missions_grouped[\"MISSIONS_LIST\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print (missions_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = fulldf.merge(missions_grouped, on=\"USER_ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_6</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "      <th>LANGUAGE_PROFILE</th>\n",
       "      <th>MISSIONS_LIST</th>\n",
       "      <th>MISSIONS_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "      <td>[Mise en place d’un pipeline RAG pour la migra...</td>\n",
       "      <td>Mise en place d’un pipeline RAG pour la migrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 90.0, 'French': 100.0}</td>\n",
       "      <td>[Mise en œuvre d’une application de simulation...</td>\n",
       "      <td>Mise en œuvre d’une application de simulation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 50.0, 'French': 100.0}</td>\n",
       "      <td>[Intégration de données, Analyser et résoudre ...</td>\n",
       "      <td>Intégration de données Analyser et résoudre le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 60.0, 'French': 100.0}</td>\n",
       "      <td>[Analyser le système d'information financier, ...</td>\n",
       "      <td>Analyser le système d'information financier Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "      <td>[Restitution et transmission des connaissances...</td>\n",
       "      <td>Restitution et transmission des connaissances ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 80.0}</td>\n",
       "      <td>[Support aux utilisateurs finaux de niveau 2, ...</td>\n",
       "      <td>Support aux utilisateurs finaux de niveau 2 Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "      <td>[Analyses des fichiers Excel utilisés pour aut...</td>\n",
       "      <td>Analyses des fichiers Excel utilisés pour auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 80.0, 'French': 100.0}</td>\n",
       "      <td>[**Business Analyst for the implementation of ...</td>\n",
       "      <td>**Business Analyst for the implementation of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 70.0, 'French': 100.0}</td>\n",
       "      <td>[Design and implementation of data architectur...</td>\n",
       "      <td>Design and implementation of data architecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'English': 80.0}</td>\n",
       "      <td>[Atelier de travail avec le [CLIENT] pour comp...</td>\n",
       "      <td>Atelier de travail avec le [CLIENT] pour compr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  ... MONTH_6 MONTH_7  \\\n",
       "0                                                  NaN  ...     100     100   \n",
       "1                                                  NaN  ...     100     100   \n",
       "2                                                  NaN  ...      25      25   \n",
       "3                                                  NaN  ...      25      25   \n",
       "4                                                  NaN  ...      25      50   \n",
       "..                                                 ...  ...     ...     ...   \n",
       "114                                                NaN  ...      25      25   \n",
       "115                                                NaN  ...       0       0   \n",
       "116                                                NaN  ...       0       0   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...  ...      25      25   \n",
       "118                                                NaN  ...      25      50   \n",
       "\n",
       "    MONTH_8 MONTH_9  MONTH_10  MONTH_11  MONTH_12  \\\n",
       "0       100     100       100       100       100   \n",
       "1       100     100       100       100       100   \n",
       "2        25      25        25        25        25   \n",
       "3        25      50        25        25        25   \n",
       "4        25      25        25        25        25   \n",
       "..      ...     ...       ...       ...       ...   \n",
       "114      25      25        25        25        25   \n",
       "115       0       0         0         0         0   \n",
       "116       0       0         0         0         0   \n",
       "117      50      25        25        25        25   \n",
       "118      50      50        50        50        50   \n",
       "\n",
       "                        LANGUAGE_PROFILE  \\\n",
       "0    {'English': 100.0, 'French': 100.0}   \n",
       "1     {'English': 90.0, 'French': 100.0}   \n",
       "2     {'English': 50.0, 'French': 100.0}   \n",
       "3     {'English': 60.0, 'French': 100.0}   \n",
       "4    {'English': 100.0, 'French': 100.0}   \n",
       "..                                   ...   \n",
       "114   {'English': 100.0, 'French': 80.0}   \n",
       "115  {'English': 100.0, 'French': 100.0}   \n",
       "116   {'English': 80.0, 'French': 100.0}   \n",
       "117   {'English': 70.0, 'French': 100.0}   \n",
       "118                    {'English': 80.0}   \n",
       "\n",
       "                                         MISSIONS_LIST  \\\n",
       "0    [Mise en place d’un pipeline RAG pour la migra...   \n",
       "1    [Mise en œuvre d’une application de simulation...   \n",
       "2    [Intégration de données, Analyser et résoudre ...   \n",
       "3    [Analyser le système d'information financier, ...   \n",
       "4    [Restitution et transmission des connaissances...   \n",
       "..                                                 ...   \n",
       "114  [Support aux utilisateurs finaux de niveau 2, ...   \n",
       "115  [Analyses des fichiers Excel utilisés pour aut...   \n",
       "116  [**Business Analyst for the implementation of ...   \n",
       "117  [Design and implementation of data architectur...   \n",
       "118  [Atelier de travail avec le [CLIENT] pour comp...   \n",
       "\n",
       "                                         MISSIONS_TEXT  \n",
       "0    Mise en place d’un pipeline RAG pour la migrat...  \n",
       "1    Mise en œuvre d’une application de simulation ...  \n",
       "2    Intégration de données Analyser et résoudre le...  \n",
       "3    Analyser le système d'information financier Co...  \n",
       "4    Restitution et transmission des connaissances ...  \n",
       "..                                                 ...  \n",
       "114  Support aux utilisateurs finaux de niveau 2 Pr...  \n",
       "115  Analyses des fichiers Excel utilisés pour auto...  \n",
       "116  **Business Analyst for the implementation of a...  \n",
       "117  Design and implementation of data architecture...  \n",
       "118  Atelier de travail avec le [CLIENT] pour compr...  \n",
       "\n",
       "[119 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.to_csv(\"full_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HCK_HEC_LANG.csv', '.DS_Store', 'HCK_HEC_XP.csv', 'HCK_HEC_SKILLS.csv', 'HCK_HEC_USER.csv', 'HCK_HEC_STAFFING.csv', 'raw']\n"
     ]
    }
   ],
   "source": [
    "if 'project_root' not in globals():\n",
    "    current_dir = os.getcwd()\n",
    "    if os.path.basename(current_dir) == 'notebooks':\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "full_df = pd.read_csv(\n",
    "    os.path.join(project_root, \"full_df.csv\"),\n",
    "    sep=',', \n",
    "    on_bad_lines='skip', \n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[\"USER_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine tuning bert for paraphrase detection (are the two sentences paraphrases of each other?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade datasets sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datasets import Dataset\n",
    "sys.modules['datasets'].Dataset = Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# language finteuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 140 examples\n",
      "Positive pairs: 109, Negative pairs: 31\n",
      "  - Data Engineer pairs: 36\n",
      "  - Scrum Master pairs: 16\n",
      "  - Data Analyst pairs: 22\n",
      "  - Healthcare pairs: 18\n",
      "  - Finance pairs: 17\n",
      "Using ContrastiveLoss with margin=0.5\n",
      "This fine-tuning will make English sentences match their French equivalents across all job categories\n",
      "Starting training for 5 epochs...\n",
      "Total steps: 45\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 9/9 [00:41<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0163\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 9/9 [00:36<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0130\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 9/9 [00:36<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0111\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 9/9 [00:36<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0092\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 9/9 [00:36<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0082\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# Fine-tuning for English-French translation matching across all job categories\n",
    "# Positive pairs: English sentences matched with their French equivalents for each job role\n",
    "\n",
    "# DATA ENGINEER - English-French pairs\n",
    "data_engineer_pairs = [\n",
    "    (\"Design and develop robust and optimized data ingestion pipelines using Azure Data Factory\",\n",
    "     \"Concevoir et développer des pipelines d'ingestion de données robustes et optimisés à l'aide d'Azure Data Factory\"),\n",
    "    (\"Develop complex transformations using Apache Spark (Scala/Python) in Azure Databricks\",\n",
    "     \"Développer des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "    (\"Implement streaming and batch data flows via Databricks Streaming and Apache Kafka\",\n",
    "     \"Implémenter des flux de données streaming et batch via Databricks Streaming et Apache Kafka\"),\n",
    "    (\"Created data pipelines using ADF\",\n",
    "     \"Concevoir des pipelines d'ingestion de données avec Azure Data Factory\"),\n",
    "    (\"Participate in defining and implementing data models adapted to analytical needs\",\n",
    "     \"Participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques\"),\n",
    "    (\"Implement data quality validation processes\",\n",
    "     \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Automate pipeline deployments and tests via Azure DevOps\",\n",
    "     \"Automatiser les déploiements et les tests des pipelines via Azure DevOps\"),\n",
    "    (\"Document developed solutions according to internal standards\",\n",
    "     \"Documenter les solutions développées selon les normes internes\"),\n",
    "    (\"Collaborate with Data Science, BI, and IT Infrastructure teams\",\n",
    "     \"Travailler en collaboration avec les équipes Data Science, BI et IT Infrastructure\"),\n",
    "    (\"Contribute to the development of data architecture and data governance principles\",\n",
    "     \"Participer à l'élaboration des principes d'architecture data et de gouvernance des données\"),\n",
    "    (\"Created data pipelines using ADF\", \"Concevoir des pipelines d’ingestion de données avec Azure Data Factory\"),\n",
    "    (\"Develop complex transformations using Apache Spark\", \"Développer des transformations complexes avec Apache Spark\"),\n",
    "    (\"Developed PySpark jobs on Databricks\", \"Créer des transformations complexes avec Spark dans Azure Databricks\"),\n",
    "    (\"Monitored and maintained ADF pipelines in production\", \"Assurer la qualité et la fiabilité des pipelines dans Azure Data Factory\"),\n",
    "    (\"Improved data quality checks in Spark pipelines\", \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Utilisation de Synapse serverless et création de workspace\", \"Développer des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "    (\"Utilisation de Azure DevOps pour gérer les environnements\", \"Automatiser les déploiements et les tests des pipelines via Azure DevOps\"),\n",
    "    (\"Developed complex transformations using Apache Spark\", \"Développer des transformations complexes avec Apache Spark\"),\n",
    "    (\"Implemented streaming and batch data flows via Databricks\", \"Implémenter des flux de données streaming et batch via Databricks Streaming\"),\n",
    "    (\"Automate pipeline deployments and tests via Azure DevOps\", \"Automatiser les déploiements et les tests des pipelines via Azure DevOps\"),\n",
    "    (\"Contribute to the development of data architecture and data governance principles\", \"Contribuer à l'élaboration des principes d'architecture data et de gouvernance des données\"),\n",
    "    (\"Built CI/CD workflows using Azure DevOps\", \"Automatiser les déploiements via Azure DevOps (CI/CD)\"),\n",
    "    (\"Designed a lakehouse architecture\", \"Participer à l’élaboration de l’architecture data\"),\n",
    "    (\"Protected team focus from outside distractions\", \"Protéger l’équipe des interférences externes\"),\n",
    "    (\"Création de modèles de données en étoile avec gestion des SCD2\", \"Participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques\"),\n",
    "    (\"Mise en place de Snowflake, gestion des droits, objets, dynamic tables\", \"Contribuer à l’élaboration des principes d’architecture data et de gouvernance des données\"),\n",
    "    (\"Réalisation d’analyses de performance sur Snowflake\", \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Performed data integration from CRM and Google Analytics\", \"Intégrer les données issues de diverses plateformes (Google Analytics, CRM...)\"),\n",
    "    (\"Designed data models aligned with business goals\", \"Concevoir des modèles de données adaptés aux objectifs métiers\"),\n",
    "    (\"Analyzed sales trends and generated insights for decision making\", \"Analyser les tendances de vente et générer des insights pour la prise de décision\"),\n",
    "    (\"Removed impediments blocking team progress\", \"Supprimer les obstacles bloquant la progression de l'équipe\"),\n",
    "    (\"Participate in defining and implementing data models\", \"Participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques\"),\n",
    "    (\"Implement data quality validation processes\", \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Document developed solutions according to internal standards\", \"Documenter les solutions développées selon les normes internes\"),\n",
    "    (\"Collaborate with Data Science, BI, and IT Infrastructure teams\", \"Travailler en collaboration avec les équipes Data Science, BI et IT Infrastructure\"),\n",
    "    (\"Intégration de données depuis des fichiers Excel et des systèmes externes\", \"Intégrer les données issues de diverses plateformes (Google Analytics, CRM...)\"),\n",
    "]\n",
    "\n",
    "# SCRUM MASTER - English-French pairs\n",
    "scrum_master_pairs = [\n",
    "    (\"Facilitated Scrum ceremonies including planning and retrospectives\",\n",
    "     \"Faciliter l'ensemble des cérémonies Scrum\"),\n",
    "    (\"Acted as Agile coach for cross-functional team\",\n",
    "     \"Agir en tant que coach Agile\"),\n",
    "    (\"Helped Product Owner manage backlog and define priorities\",\n",
    "     \"Aider le Product Owner à gérer efficacement le backlog produit\"),\n",
    "    (\"Tracked team velocity and analyzed sprint metrics\",\n",
    "     \"Mesurer et analyser la performance de l'équipe via des indicateurs clés\"),\n",
    "    (\"Protected team from external distractions\",\n",
    "     \"Protéger l'équipe des interférences externes\"),\n",
    "    (\"Organized daily standup meetings and sprint planning sessions\",\n",
    "     \"Organiser les réunions quotidiennes et les sessions de planification de sprint\"),\n",
    "    (\"Removed impediments blocking team progress\",\n",
    "     \"Supprimer les obstacles bloquant la progression de l'équipe\"),\n",
    "    (\"Coached team on Agile methodologies and best practices\",\n",
    "     \"Coacher l'équipe sur les méthodologies Agile et les meilleures pratiques\"),\n",
    "    (\"Helped PO with backlog prioritization\", \"Aider le Product Owner à gérer efficacement le backlog produit\"),\n",
    "    (\"Facilitated daily standups and retrospectives\", \"Animer les cérémonies Scrum (daily, rétrospective, sprint planning)\"),\n",
    "    (\"Facilitation des cérémonies Agile (Daily, Rétro, Planning)\", \"Faciliter l’ensemble des cérémonies Scrum\"),\n",
    "    (\"Accompagnement des équipes pour adopter les pratiques Agile\", \"Agir en tant que coach Agile\"),\n",
    "    (\"Soutien au Product Owner dans la priorisation du backlog\", \"Aider le Product Owner à gérer efficacement le backlog produit\"),\n",
    "    (\"Tracked team velocity and analyzed sprint metrics\", \"Mesurer et analyser la performance de l'équipe via des indicateurs clés\"),\n",
    "    (\"Coached team on Agile methodologies and best practices\", \"Coacher l'équipe sur les méthodologies Agile et les meilleures pratiques\"),\n",
    "    (\"Organized daily standup meetings and sprint planning sessions\", \"Organiser les réunions quotidiennes et les sessions de planification de sprint\"),\n",
    "]\n",
    "\n",
    "# DATA ANALYST - English-French pairs\n",
    "data_analyst_pairs = [\n",
    "    (\"Built dashboards in Power BI\",\n",
    "     \"Créer des tableaux de bord Power BI\"),\n",
    "    (\"Created interactive reports and visualizations for business stakeholders\",\n",
    "     \"Créer des rapports interactifs et des visualisations pour les parties prenantes\"),\n",
    "    (\"Wrote performant SQL queries to transform marketing data\",\n",
    "     \"Rédiger du code SQL performant\"),\n",
    "    (\"Performed data integration from CRM and Google Analytics\",\n",
    "     \"Intégrer les données issues de diverses plateformes (Google Analytics, CRM...)\"),\n",
    "    (\"Collaborated with analysts to understand reporting needs\",\n",
    "     \"Collaborer étroitement avec les analystes pour comprendre leurs besoins\"),\n",
    "    (\"Designed data models aligned with business goals\",\n",
    "     \"Concevoir des modèles de données adaptés aux objectifs métiers\"),\n",
    "    (\"Analyzed sales trends and generated insights for decision making\",\n",
    "     \"Analyser les tendances de vente et générer des insights pour la prise de décision\"),\n",
    "    (\"Created KPI dashboards to track business performance\",\n",
    "     \"Créer des tableaux de bord KPI pour suivre la performance de l'entreprise\"),\n",
    "    (\"Built dashboards in Power BI\", \"Créer des tableaux de bord Power BI\"),\n",
    "    (\"Worked closely with stakeholders to define KPIs and dashboards\", \"Collaborer avec les analystes pour concevoir des tableaux de bord métier\"),\n",
    "    (\"Wrote optimized SQL for analytics reporting\", \"Rédiger du code SQL performant pour l’analyse de données\"),\n",
    "    (\"Worked with BI and data science to align reporting\", \"Travailler en collaboration avec les équipes Data Science, BI et IT\"),\n",
    "    (\"Analyse des KPIs projet et amélioration continue\", \"Mesurer et analyser la performance de l’équipe via des indicateurs clés\"),\n",
    "    (\"Prepared financial reports and budget variance analysis\", \"Préparer les rapports financiers et l'analyse des écarts budgétaires\"),\n",
    "    (\"Préparation de rapports financiers et analyse des écarts\", \"Prepared financial reports and budget variance analysis\"),\n",
    "    (\"Created interactive reports and visualizations for business stakeholders\", \"Créer des rapports interactifs et des visualisations pour les parties prenantes\"),\n",
    "    (\"Wrote performant SQL queries to transform marketing data\", \"Rédiger du code SQL performant pour transformer les données marketing\"),\n",
    "    (\"Created KPI dashboards to track business performance\", \"Créer des tableaux de bord KPI pour suivre la performance de l'entreprise\"),\n",
    "    (\"Collaborated with analysts to understand reporting needs\", \"Collaborer étroitement avec les analystes pour comprendre leurs besoins\"),\n",
    "    (\"Création de rapports Power BI à partir de sources SQL Server\", \"Développer des tableaux de bord et rapports dans Power BI\"),\n",
    "    (\"Écriture de requêtes SQL complexes pour extraire des indicateurs clés\", \"Rédiger du code SQL performant\"),\n",
    "    (\"Collaboration avec les analystes pour définir des rapports pertinents\", \"Collaborer étroitement avec les analystes pour comprendre leurs besoins\"),\n",
    "]\n",
    "\n",
    "# HEALTHCARE - English-French pairs\n",
    "healthcare_pairs = [\n",
    "    (\"Analyzed patient medical records to establish accurate diagnosis\",\n",
    "     \"Analyser les dossiers médicaux des patients pour établir un diagnostic précis\"),\n",
    "    (\"Coordinated care with medical team and healthcare professionals\",\n",
    "     \"Coordonner les soins avec l'équipe médicale et les professionnels de santé\"),\n",
    "    (\"Implemented patient record management system and clinical treatments\",\n",
    "     \"Mettre en place un système de gestion des dossiers patients et des traitements cliniques\"),\n",
    "    (\"Assisted physicians in patient care and treatment planning\",\n",
    "     \"Assister les médecins dans les soins aux patients et la planification des traitements\"),\n",
    "    (\"Managed clinical documentation and medical records\",\n",
    "     \"Gérer la documentation clinique et les dossiers médicaux\"),\n",
    "    (\"Collaborated with nursing staff on patient care protocols\",\n",
    "     \"Collaborer avec le personnel infirmier sur les protocoles de soins aux patients\"),\n",
    "    (\"Analyzed patient medical records to establish accurate diagnosis\", \"Analyser les dossiers médicaux des patients pour établir un diagnostic précis\"),\n",
    "    (\"Coordinated care with medical team and healthcare professionals\", \"Coordonner les soins avec l'équipe médicale et les professionnels de santé\"),\n",
    "    (\"Implemented patient record management system and clinical treatments\", \"Mettre en place un système de gestion des dossiers patients et des traitements cliniques\"),\n",
    "    (\"Assisted physicians in patient care and treatment planning\", \"Assister les médecins dans les soins aux patients et la planification des traitements\"),\n",
    "    (\"Managed clinical documentation and medical records\", \"Gérer la documentation clinique et les dossiers médicaux\"),\n",
    "    (\"Collaborated with nursing staff on patient care protocols\", \"Collaborer avec le personnel infirmier sur les protocoles de soins aux patients\"),\n",
    "    (\"Conducted patient assessments and health screenings\", \"Réaliser des évaluations de patients et des dépistages de santé\"),\n",
    "    (\"Monitored patient vital signs and medication administration\", \"Surveiller les signes vitaux des patients et l'administration de médicaments\"),\n",
    "    (\"Analyse des dossiers médicaux pour établir un diagnostic\", \"Analyzed patient medical records to establish accurate diagnosis\"),\n",
    "    (\"Coordination des soins avec l'équipe médicale\", \"Coordinated care with medical team and healthcare professionals\"),\n",
    "    (\"Gestion des dossiers patients et traitements cliniques\", \"Managed patient records and clinical treatment protocols\"),\n",
    "    (\"Assistance aux médecins dans les soins aux patients\", \"Assisted physicians in patient care and treatment planning\"),\n",
    "]\n",
    "\n",
    "# FINANCE - English-French pairs\n",
    "finance_pairs = [\n",
    "    (\"Implemented budget simulation application and rolling forecast\",\n",
    "     \"Mise en œuvre d'une application de simulation budgétaire et de rolling forecast\"),\n",
    "    (\"Optimized financial close processes and budget planning\",\n",
    "     \"Optimisation des processus de clôture financière et de planification budgétaire\"),\n",
    "    (\"Designed and implemented cost allocation application for monthly forecast process\",\n",
    "     \"Conception et mise en œuvre d'une application d'allocation de coûts pour le processus de forecast mensuel\"),\n",
    "    (\"Conducted financial audits and compliance reviews\",\n",
    "     \"Réaliser des audits financiers et des revues de conformité\"),\n",
    "    (\"Prepared financial reports and budget variance analysis\",\n",
    "     \"Préparer les rapports financiers et l'analyse des écarts budgétaires\"),\n",
    "    (\"Managed financial planning and analysis activities\",\n",
    "     \"Gérer les activités de planification et d'analyse financières\"),\n",
    "    (\"Implemented budget simulation application and rolling forecast\", \"Mise en œuvre d'une application de simulation budgétaire et de rolling forecast\"),\n",
    "    (\"Optimized financial close processes and budget planning\", \"Optimisation des processus de clôture financière et de planification budgétaire\"),\n",
    "    (\"Designed and implemented cost allocation application for monthly forecast process\", \"Conception et mise en œuvre d'une application d'allocation de coûts pour le processus de forecast mensuel\"),\n",
    "    (\"Conducted financial audits and compliance reviews\", \"Réaliser des audits financiers et des revues de conformité\"),\n",
    "    (\"Managed financial planning and analysis activities\", \"Gérer les activités de planification et d'analyse financières\"),\n",
    "    (\"Developed financial models for forecasting and budgeting\", \"Développer des modèles financiers pour la prévision et la budgétisation\"),\n",
    "    (\"Analyzed financial data to support strategic decision making\", \"Analyser les données financières pour soutenir la prise de décision stratégique\"),\n",
    "    (\"Mise en œuvre d'une application de simulation budgétaire\", \"Implemented budget simulation application and rolling forecast\"),\n",
    "    (\"Optimisation des processus de clôture financière\", \"Optimized financial close processes and budget planning\"),\n",
    "    (\"Réalisation d'audits financiers et revues de conformité\", \"Conducted financial audits and compliance reviews\"),\n",
    "    (\"Gestion de la planification et analyse financières\", \"Managed financial planning and analysis activities\"),\n",
    "]\n",
    "\n",
    "\n",
    "positive_pairs = (\n",
    "    data_engineer_pairs +\n",
    "    scrum_master_pairs +\n",
    "    data_analyst_pairs +\n",
    "    healthcare_pairs +\n",
    "    finance_pairs\n",
    ")\n",
    "\n",
    "\n",
    "negative_pairs = [\n",
    "    (\"Built dashboards in Power BI\", \"Préparer des repas en cuisine\"),\n",
    "    (\"Created REST APIs\", \"Aider les patients dans les soins\"),\n",
    "    (\"Facilitated Scrum ceremonies\", \"Développer des pipelines ETL\"),\n",
    "    (\"Analyzed patient medical records\", \"Optimiser les processus de clôture financière\"),\n",
    "    (\"Implemented budget simulation\", \"Faciliter les cérémonies Scrum\"),\n",
    "    (\"Developed PySpark jobs\", \"Coordonner les soins avec l'équipe médicale\"),\n",
    "    (\"Automated deployment with Azure DevOps\", \"Gérer les présences dans un club de sport\"),\n",
    "    (\"Helped define data architecture\", \"Traduire un document marketing en espagnol\"),\n",
    "    (\"Documented pipelines\", \"Rédiger une lettre de motivation\"),\n",
    "    (\"Conducted financial audits\", \"Agir en tant que coach Agile\"),\n",
    "    (\"Developed PySpark jobs\", \"Animer un atelier marketing\"),\n",
    "    (\"Implemented Kafka streaming\", \"Créer du contenu pour les réseaux sociaux\"),\n",
    "    (\"Documented pipelines\", \"Traduire un document marketing\"),\n",
    "    (\"Designed KPI dashboards\", \"Agir en tant que coach Agile (Scrum Master)\"),\n",
    "    (\"Helped organize hackathon logistics\", \"Construire des pipelines avec Apache Spark\"),\n",
    "    (\"Création de dashboards dans Power BI\", \"Automatiser les déploiements et les tests des pipelines via Azure DevOps\"),\n",
    "    (\"Faciliter les cérémonies Scrum\", \"Développer des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "    (\"Élaboration de reporting mensuel\", \"Documenter les solutions développées selon les normes internes\"),\n",
    "    (\"Écriture de requêtes SQL pour KPIs marketing\", \"Contribuer à l’élaboration des principes d’architecture data et de gouvernance des données\"),\n",
    "    (\"Built dashboards in Power BI\", \"Cuisiner un repas gastronomique\"),\n",
    "    (\"Developed PySpark jobs\", \"Enseigner les mathématiques à des étudiants\"),\n",
    "    (\"Facilitated Scrum ceremonies\", \"Réparer une voiture en panne\"),\n",
    "    (\"Analyzed patient medical records\", \"Créer une œuvre d'art contemporain\"),\n",
    "    (\"Implemented budget simulation\", \"Organiser un événement de mariage\"),\n",
    "    (\"Created data pipelines\", \"Traduire un livre de poésie\"),\n",
    "    (\"Monitored ADF pipelines\", \"Diriger un orchestre symphonique\"),\n",
    "    (\"Wrote SQL queries\", \"Peindre un tableau à l'huile\"),\n",
    "    (\"Helped PO with backlog\", \"Concevoir une collection de mode\"),\n",
    "    (\"Coordinated care with medical team\", \"Développer une application mobile de jeu\"),\n",
    "    (\"Conducted financial audits\", \"Écrire un scénario de film\"),\n",
    "    (\"Prepared financial reports\", \"Créer une chorégraphie de danse\"),\n",
    "]\n",
    "\n",
    "train_examples = [\n",
    "    InputExample(texts=[text1, text2], label=1.0) for text1, text2 in positive_pairs\n",
    "] + [\n",
    "    InputExample(texts=[text1, text2], label=0.0) for text1, text2 in negative_pairs\n",
    "]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    return batch\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16, collate_fn=collate_fn)  # Increased from 1\n",
    "\n",
    "\n",
    "train_loss = losses.ContrastiveLoss(\n",
    "    model,\n",
    "    distance_metric=losses.SiameseDistanceMetric.COSINE_DISTANCE,\n",
    "    margin=0.5  \n",
    ")\n",
    "\n",
    "print(f\"Training with {len(train_examples)} examples\")\n",
    "print(f\"Positive pairs: {len(positive_pairs)}, Negative pairs: {len(negative_pairs)}\")\n",
    "print(f\"  - Data Engineer pairs: {len(data_engineer_pairs)}\")\n",
    "print(f\"  - Scrum Master pairs: {len(scrum_master_pairs)}\")\n",
    "print(f\"  - Data Analyst pairs: {len(data_analyst_pairs)}\")\n",
    "print(f\"  - Healthcare pairs: {len(healthcare_pairs)}\")\n",
    "print(f\"  - Finance pairs: {len(finance_pairs)}\")\n",
    "print(f\"Using ContrastiveLoss with margin=0.5\")\n",
    "print(\"This fine-tuning will make English sentences match their French equivalents across all job categories\")\n",
    "\n",
    "import sys\n",
    "\n",
    "if 'datasets' not in sys.modules:\n",
    "    import datasets\n",
    "    sys.modules['datasets'] = datasets\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "import torch\n",
    "device = torch.device('cpu') #no gpu\n",
    "model = model.to(device)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 5\n",
    "warmup_steps = 100\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "current_step = 0\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(f\"Total steps: {total_steps}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")):\n",
    "        batch_losses = []\n",
    "        \n",
    "        for example in batch:\n",
    "\n",
    "            text1, text2 = example.texts\n",
    "            label = example.label\n",
    "            \n",
    "            features1 = model.tokenize([text1])\n",
    "            features2 = model.tokenize([text2])\n",
    "            \n",
    "            features1 = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in features1.items()}\n",
    "            features2 = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in features2.items()}\n",
    "            \n",
    "            sentence_features = [features1, features2]\n",
    "            labels = torch.tensor([label], dtype=torch.float32, device=device)\n",
    "            \n",
    "            loss = train_loss(sentence_features, labels)\n",
    "            \n",
    "            batch_losses.append(loss)\n",
    "        \n",
    "        if batch_losses:\n",
    "            avg_batch_loss = sum(batch_losses) / len(batch_losses)\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            avg_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            step = current_step + batch_idx\n",
    "            if step < warmup_steps:\n",
    "                lr_scale = min(1.0, float(step + 1) / warmup_steps)\n",
    "                for pg in optimizer.param_groups:\n",
    "                    pg['lr'] = 2e-5 * lr_scale\n",
    "            \n",
    "            epoch_loss += avg_batch_loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Average loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "model.save(\"modelfinetuned1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# further finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#import subprocess\n",
    "\n",
    "#subprocess.check_call([\n",
    "    #sys.executable, \"-m\", \"pip\", \"install\", \"accelerate>=0.26.0\"\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'modelfinetuned1' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original avg:  0.794\n",
      "Finetuned avg:0.881\n",
      "Delta: +0.087 (+11.0%)\n",
      "Pairs (orig -> finetuned):\n",
      "- Built dashboards in Power BI...: 0.766 -> 0.894 (+0.128, +16.7%)\n",
      "- Developed PySpark jobs on Databricks...: 0.551 -> 0.757 (+0.206, +37.4%)\n",
      "- Facilitated daily standups and retrospectives...: 0.430 -> 0.665 (+0.235, +54.6%)\n",
      "- Analyzed patient medical records to establish...: 0.919 -> 0.953 (+0.034, +3.7%)\n",
      "- Implemented budget simulation application...: 0.493 -> 0.711 (+0.218, +44.1%)\n",
      "- Created interactive reports and visualization...: 0.861 -> 0.931 (+0.070, +8.1%)\n",
      "- Wrote performant SQL queries to transform mar...: 0.919 -> 0.947 (+0.028, +3.0%)\n",
      "- Performed data integration from CRM and Googl...: 0.858 -> 0.910 (+0.052, +6.1%)\n",
      "- Designed data models aligned with business go...: 0.845 -> 0.929 (+0.083, +9.9%)\n",
      "- Helped PO with backlog prioritization...: 0.673 -> 0.873 (+0.200, +29.7%)\n",
      "- Tracked team velocity and analyzed sprint met...: 0.612 -> 0.787 (+0.175, +28.6%)\n",
      "- Removed impediments blocking team progress...: 0.868 -> 0.911 (+0.043, +5.0%)\n",
      "- Coached team on Agile methodologies and best ...: 0.958 -> 0.973 (+0.015, +1.6%)\n",
      "- Assisted physicians in patient care and treat...: 0.924 -> 0.959 (+0.035, +3.7%)\n",
      "- Managed clinical documentation and medical re...: 0.954 -> 0.973 (+0.018, +1.9%)\n",
      "- Collaborated with nursing staff on patient ca...: 0.971 -> 0.982 (+0.012, +1.2%)\n",
      "- Conducted patient assessments and health scre...: 0.922 -> 0.952 (+0.030, +3.3%)\n",
      "- Designed and implemented cost allocation appl...: 0.914 -> 0.955 (+0.041, +4.5%)\n",
      "- Prepared financial reports and budget varianc...: 0.869 -> 0.933 (+0.064, +7.4%)\n",
      "- Developed financial models for forecasting an...: 0.954 -> 0.974 (+0.020, +2.1%)\n",
      "- Analyzed financial data to support strategic ...: 0.978 -> 0.987 (+0.009, +0.9%)\n",
      "- Created data pipelines using ADF...: 0.613 -> 0.802 (+0.189, +30.8%)\n",
      "- Monitored and maintained ADF pipelines in pro...: 0.614 -> 0.748 (+0.135, +21.9%)\n",
      "- Worked closely with stakeholders to define KP...: 0.602 -> 0.785 (+0.183, +30.4%)\n",
      "- Improved data quality checks in Spark pipelin...: 0.624 -> 0.782 (+0.158, +25.3%)\n",
      "- Built CI/CD workflows using Azure DevOps...: 0.877 -> 0.925 (+0.047, +5.4%)\n",
      "- Designed a lakehouse architecture...: 0.356 -> 0.534 (+0.178, +50.0%)\n",
      "- Worked with BI and data science to align repo...: 0.752 -> 0.853 (+0.101, +13.4%)\n",
      "- Protected team focus from outside distraction...: 0.801 -> 0.851 (+0.050, +6.3%)\n",
      "- Organized daily standup meetings and sprint p...: 0.865 -> 0.943 (+0.078, +9.0%)\n",
      "- Removed impediments blocking team progress...: 0.868 -> 0.911 (+0.043, +5.0%)\n",
      "- Coached team on Agile methodologies and best ...: 0.958 -> 0.973 (+0.015, +1.6%)\n",
      "- Created KPI dashboards to track business perf...: 0.897 -> 0.945 (+0.048, +5.3%)\n",
      "- Collaborated with analysts to understand repo...: 0.814 -> 0.921 (+0.107, +13.1%)\n",
      "- Analyzed sales trends and generated insights ...: 0.960 -> 0.975 (+0.015, +1.6%)\n",
      "- Coordinated care with medical team and health...: 0.959 -> 0.974 (+0.016, +1.6%)\n",
      "- Implemented patient record management system ...: 0.820 -> 0.906 (+0.086, +10.5%)\n",
      "- Monitored patient vital signs and medication ...: 0.922 -> 0.951 (+0.029, +3.2%)\n",
      "- Optimized financial close processes and budge...: 0.907 -> 0.950 (+0.043, +4.7%)\n",
      "- Conducted financial audits and compliance rev...: 0.953 -> 0.968 (+0.016, +1.7%)\n",
      "- Managed financial planning and analysis activ...: 0.975 -> 0.985 (+0.011, +1.1%)\n",
      "- Developed complex transformations using Apach...: 0.978 -> 0.981 (+0.003, +0.3%)\n",
      "- Implemented streaming and batch data flows vi...: 0.954 -> 0.973 (+0.018, +1.9%)\n",
      "- Participate in defining and implementing data...: 0.866 -> 0.924 (+0.058, +6.7%)\n",
      "- Implement data quality validation processes...: 0.955 -> 0.980 (+0.026, +2.7%)\n",
      "- Automate pipeline deployments and tests via A...: 0.977 -> 0.985 (+0.008, +0.9%)\n",
      "- Document developed solutions according to int...: 0.867 -> 0.928 (+0.061, +7.0%)\n",
      "- Collaborate with Data Science, BI, and IT Inf...: 0.987 -> 0.991 (+0.004, +0.4%)\n",
      "- Contribute to the development of data archite...: 0.980 -> 0.986 (+0.006, +0.6%)\n",
      "- Implémentation et automatisation sur Azure Da...: 0.694 -> 0.835 (+0.141, +20.4%)\n",
      "- Utilisation de Synapse serverless et création...: 0.371 -> 0.648 (+0.277, +74.7%)\n",
      "- Création de modèles de données en étoile avec...: 0.500 -> 0.734 (+0.235, +47.0%)\n",
      "- Mise en place de Snowflake, gestion des droit...: 0.426 -> 0.669 (+0.244, +57.3%)\n",
      "- Réalisation d'analyses de performance sur Sno...: 0.382 -> 0.636 (+0.253, +66.3%)\n",
      "- Facilitation des cérémonies Agile (Daily, Rét...: 0.623 -> 0.805 (+0.182, +29.3%)\n",
      "- Accompagnement des équipes pour adopter les p...: 0.713 -> 0.771 (+0.058, +8.1%)\n",
      "- Soutien au Product Owner dans la priorisation...: 0.898 -> 0.941 (+0.043, +4.8%)\n",
      "- Analyse des KPIs projet et amélioration conti...: 0.483 -> 0.669 (+0.185, +38.4%)\n",
      "\n",
      "======================================================================\n",
      "WRONG TRANSLATIONS (should have LOW similarity)\n",
      "======================================================================\n",
      "Original Model Average:     0.206\n",
      "Fine-tuned Model Average:   0.362\n",
      "Change:                     +0.157 (+76.0%)\n",
      "(Lower is better - model should push wrong translations apart)\n",
      "\n",
      "Individual wrong pairs (orig -> finetuned):\n",
      "  WORSE | 0.316 -> 0.579 (+0.263, +83.4%) | Design and develop robust data pipelines... vs Créer des tableaux de bord Power BI...\n",
      "  WORSE | 0.204 -> 0.344 (+0.139, +68.2%) | Facilitated Scrum ceremonies including p... vs Analyser les dossiers médicaux des patie...\n",
      "  WORSE | 0.325 -> 0.550 (+0.225, +69.4%) | Built dashboards in Power BI... vs Mise en œuvre d'une application de simul...\n",
      "  WORSE | 0.096 -> 0.231 (+0.135, +140.9%) | Analyzed patient medical records to esta... vs Faciliter l'ensemble des cérémonies Scru...\n",
      "  WORSE | 0.411 -> 0.602 (+0.191, +46.6%) | Implemented budget simulation applicatio... vs Concevoir et développer des pipelines de...\n",
      "  WORSE | 0.193 -> 0.268 (+0.075, +39.2%) | Developed PySpark jobs on Databricks... vs Préparer des repas en cuisine...\n",
      "  WORSE | -0.028 -> 0.071 (+0.099, +0.0%) | Created data pipelines using ADF... vs Organiser un événement de mariage...\n",
      "  WORSE | 0.132 -> 0.255 (+0.123, +93.8%) | Facilitated daily standups and retrospec... vs Cuisiner un repas gastronomique...\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Correct translations: 0.794 -> 0.881 (+0.087, +93.8%)\n",
      "Wrong translations:   0.206 -> 0.362 (+0.157, +76.0%)\n",
      "\n",
      "Gap (correct - wrong): Original: 0.588, Fine-tuned: 0.519\n",
      "Gap improvement: -0.069 (larger gap = better discrimination)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "orig_model = SentenceTransformer( \"paraphrase-multilingual-mpnet-base-v2\")\n",
    "finetuned_model = SentenceTransformer(\"modelfinetuned1\")\n",
    "\n",
    "def sim(model, t1, t2):\n",
    "    return util.pytorch_cos_sim(\n",
    "        model.encode(t1, convert_to_tensor=True),\n",
    "        model.encode(t2, convert_to_tensor=True)\n",
    "    ).item()\n",
    "\n",
    "en_fr_pairs = [\n",
    "    (\"Built dashboards in Power BI\", \"Créer des tableaux de bord Power BI\"),\n",
    "    (\"Developed PySpark jobs on Databricks\", \"Créer des transformations complexes avec Spark dans Azure Databricks\"),\n",
    "    (\"Facilitated daily standups and retrospectives\", \"Animer les cérémonies Scrum\"),\n",
    "    (\"Analyzed patient medical records to establish accurate diagnosis\", \"Analyser les dossiers médicaux des patients pour établir un diagnostic précis\"),\n",
    "    (\"Implemented budget simulation application\", \"Mise en œuvre d'une application de simulation budgétaire\"),\n",
    "    (\"Created interactive reports and visualizations for business stakeholders\", \"Créer des rapports interactifs et des visualisations pour les parties prenantes\"),\n",
    "    (\"Wrote performant SQL queries to transform marketing data\", \"Rédiger du code SQL performant pour transformer les données marketing\"),\n",
    "    (\"Performed data integration from CRM and Google Analytics\", \"Intégrer les données issues de diverses plateformes (Google Analytics, CRM...)\"),\n",
    "    (\"Designed data models aligned with business goals\", \"Concevoir des modèles de données adaptés aux objectifs métiers\"),\n",
    "    (\"Helped PO with backlog prioritization\", \"Aider le Product Owner à gérer efficacement le backlog produit\"),\n",
    "    (\"Tracked team velocity and analyzed sprint metrics\", \"Mesurer et analyser la performance de l'équipe via des indicateurs clés\"),\n",
    "    (\"Removed impediments blocking team progress\", \"Supprimer les obstacles bloquant la progression de l'équipe\"),\n",
    "    (\"Coached team on Agile methodologies and best practices\", \"Coacher l'équipe sur les méthodologies Agile et les meilleures pratiques\"),\n",
    "    (\"Assisted physicians in patient care and treatment planning\", \"Assister les médecins dans les soins aux patients et la planification des traitements\"),\n",
    "    (\"Managed clinical documentation and medical records\", \"Gérer la documentation clinique et les dossiers médicaux\"),\n",
    "    (\"Collaborated with nursing staff on patient care protocols\", \"Collaborer avec le personnel infirmier sur les protocoles de soins aux patients\"),\n",
    "    (\"Conducted patient assessments and health screenings\", \"Réaliser des évaluations de patients et des dépistages de santé\"),\n",
    "    (\"Designed and implemented cost allocation application\", \"Conception et mise en œuvre d'une application d'allocation de coûts\"),\n",
    "    (\"Prepared financial reports and budget variance analysis\", \"Préparer les rapports financiers et l'analyse des écarts budgétaires\"),\n",
    "    (\"Developed financial models for forecasting and budgeting\", \"Développer des modèles financiers pour la prévision et la budgétisation\"),\n",
    "    (\"Analyzed financial data to support strategic decision making\", \"Analyser les données financières pour soutenir la prise de décision stratégique\"),\n",
    "    (\"Created data pipelines using ADF\", \"Concevoir des pipelines d'ingestion de données avec Azure Data Factory\"),\n",
    "    (\"Monitored and maintained ADF pipelines in production\", \"Assurer la qualité et la fiabilité des pipelines dans Azure Data Factory\"),\n",
    "    (\"Worked closely with stakeholders to define KPIs and dashboards\", \"Collaborer avec les analystes pour concevoir des tableaux de bord métier\"),\n",
    "    (\"Improved data quality checks in Spark pipelines\", \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Built CI/CD workflows using Azure DevOps\", \"Automatiser les déploiements via Azure DevOps (CI/CD)\"),\n",
    "    (\"Designed a lakehouse architecture\", \"Participer à l'élaboration de l'architecture data\"),\n",
    "    (\"Worked with BI and data science to align reporting\", \"Travailler en collaboration avec les équipes Data Science, BI et IT\"),\n",
    "    (\"Protected team focus from outside distractions\", \"Protéger l'équipe des interférences externes\"),\n",
    "    (\"Organized daily standup meetings and sprint planning sessions\", \"Organiser les réunions quotidiennes et les sessions de planification de sprint\"),\n",
    "    (\"Removed impediments blocking team progress\", \"Supprimer les obstacles bloquant la progression de l'équipe\"),\n",
    "    (\"Coached team on Agile methodologies and best practices\", \"Coacher l'équipe sur les méthodologies Agile et les meilleures pratiques\"),\n",
    "    (\"Created KPI dashboards to track business performance\", \"Créer des tableaux de bord KPI pour suivre la performance de l'entreprise\"),\n",
    "    (\"Collaborated with analysts to understand reporting needs\", \"Collaborer étroitement avec les analystes pour comprendre leurs besoins\"),\n",
    "    (\"Analyzed sales trends and generated insights for decision making\", \"Analyser les tendances de vente et générer des insights pour la prise de décision\"),\n",
    "    (\"Coordinated care with medical team and healthcare professionals\", \"Coordonner les soins avec l'équipe médicale et les professionnels de santé\"),\n",
    "    (\"Implemented patient record management system and clinical treatments\", \"Mettre en place un système de gestion des dossiers patients et des traitements cliniques\"),\n",
    "    (\"Monitored patient vital signs and medication administration\", \"Surveiller les signes vitaux des patients et l'administration de médicaments\"),\n",
    "    (\"Optimized financial close processes and budget planning\", \"Optimisation des processus de clôture financière et de planification budgétaire\"),\n",
    "    (\"Conducted financial audits and compliance reviews\", \"Réaliser des audits financiers et des revues de conformité\"),\n",
    "    (\"Managed financial planning and analysis activities\", \"Gérer les activités de planification et d'analyse financières\"),\n",
    "    (\"Developed complex transformations using Apache Spark\", \"Développer des transformations complexes avec Apache Spark\"),\n",
    "    (\"Implemented streaming and batch data flows via Databricks\", \"Implémenter des flux de données streaming et batch via Databricks Streaming\"),\n",
    "    (\"Participate in defining and implementing data models\", \"Participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques\"),\n",
    "    (\"Implement data quality validation processes\", \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Automate pipeline deployments and tests via Azure DevOps\", \"Automatiser les déploiements et les tests des pipelines via Azure DevOps\"),\n",
    "    (\"Document developed solutions according to internal standards\", \"Documenter les solutions développées selon les normes internes\"),\n",
    "    (\"Collaborate with Data Science, BI, and IT Infrastructure teams\", \"Travailler en collaboration avec les équipes Data Science, BI et IT Infrastructure\"),\n",
    "    (\"Contribute to the development of data architecture and data governance principles\", \"Contribuer à l'élaboration des principes d'architecture data et de gouvernance des données\"),\n",
    "    (\"Implémentation et automatisation sur Azure Data Factory (ADF)\", \"Concevoir et développer des pipelines d'ingestion de données robustes et optimisés à l'aide d'Azure Data Factory\"),\n",
    "    (\"Utilisation de Synapse serverless et création de workspace\", \"Développer des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "    (\"Création de modèles de données en étoile avec gestion des SCD2\", \"Participer à la définition et à la mise en œuvre de modèles de données adaptés aux besoins analytiques\"),\n",
    "    (\"Mise en place de Snowflake, gestion des droits, objets, dynamic tables\", \"Contribuer à l'élaboration des principes d'architecture data et de gouvernance des données\"),\n",
    "    (\"Réalisation d'analyses de performance sur Snowflake\", \"Mettre en œuvre des processus de validation de la qualité des données\"),\n",
    "    (\"Facilitation des cérémonies Agile (Daily, Rétro, Planning)\", \"Faciliter l'ensemble des cérémonies Scrum\"),\n",
    "    (\"Accompagnement des équipes pour adopter les pratiques Agile\", \"Agir en tant que coach Agile\"),\n",
    "    (\"Soutien au Product Owner dans la priorisation du backlog\", \"Aider le Product Owner à gérer efficacement le backlog produit\"),\n",
    "    (\"Analyse des KPIs projet et amélioration continue\", \"Mesurer et analyser la performance de l'équipe via des indicateurs clés\"),\n",
    "]\n",
    "\n",
    "# Wrong translations (should have LOW similarity - model should push these apart)\n",
    "wrong_translations = [\n",
    "    # Cross-domain wrong translations\n",
    "    (\"Design and develop robust data pipelines using Azure Data Factory\",\n",
    "     \"Créer des tableaux de bord Power BI\"),  # Wrong: should be about pipelines, not dashboards\n",
    "    (\"Facilitated Scrum ceremonies including planning and retrospectives\",\n",
    "     \"Analyser les dossiers médicaux des patients\"),  # Wrong: should be about Scrum, not healthcare\n",
    "    (\"Built dashboards in Power BI\",\n",
    "     \"Mise en œuvre d'une application de simulation budgétaire\"),  # Wrong: should be about dashboards, not finance\n",
    "    (\"Analyzed patient medical records to establish accurate diagnosis\",\n",
    "     \"Faciliter l'ensemble des cérémonies Scrum\"),  # Wrong: should be about healthcare, not Scrum\n",
    "    (\"Implemented budget simulation application and rolling forecast\",\n",
    "     \"Concevoir et développer des pipelines de données\"),  # Wrong: should be about finance, not data engineering\n",
    "    # Completely unrelated\n",
    "    (\"Developed PySpark jobs on Databricks\",\n",
    "     \"Préparer des repas en cuisine\"),  # Completely unrelated\n",
    "    (\"Created data pipelines using ADF\",\n",
    "     \"Organiser un événement de mariage\"),  # Completely unrelated\n",
    "    (\"Facilitated daily standups and retrospectives\",\n",
    "     \"Cuisiner un repas gastronomique\"),  # Completely unrelated\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def avg(lst): return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "orig_trans = [sim(orig_model, a, b) for a, b in en_fr_pairs]\n",
    "ft_trans   = [sim(finetuned_model, a, b) for a, b in en_fr_pairs]\n",
    "\n",
    "\n",
    "orig_trans_avg = avg(orig_trans); ft_trans_avg = avg(ft_trans)\n",
    "delta = ft_trans_avg - orig_trans_avg\n",
    "pct = delta / orig_trans_avg * 100 if orig_trans_avg > 0 else 0\n",
    "print(f\"Original avg:  {orig_trans_avg:.3f}\")\n",
    "print(f\"Finetuned avg:{ft_trans_avg:.3f}\")\n",
    "print(f\"Delta: {delta:+.3f} ({pct:+.1f}%)\")\n",
    "print(\"Pairs (orig -> finetuned):\")\n",
    "for (a, b), o, f in zip(en_fr_pairs, orig_trans, ft_trans):\n",
    "    d = f - o\n",
    "    pct = (d / o * 100) if o > 0 else 0\n",
    "    print(f\"- {a[:45]}...: {o:.3f} -> {f:.3f} ({d:+.3f}, {pct:+.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WRONG TRANSLATIONS (should have LOW similarity)\")\n",
    "print(\"=\"*70)\n",
    "orig_wrong = [sim(orig_model, a, b) for a, b in wrong_translations]\n",
    "ft_wrong = [sim(finetuned_model, a, b) for a, b in wrong_translations]\n",
    "\n",
    "orig_wrong_avg = avg(orig_wrong)\n",
    "ft_wrong_avg = avg(ft_wrong)\n",
    "wrong_delta = ft_wrong_avg - orig_wrong_avg\n",
    "wrong_pct = wrong_delta / orig_wrong_avg * 100 if orig_wrong_avg > 0 else 0\n",
    "\n",
    "print(f\"Original Model Average:     {orig_wrong_avg:.3f}\")\n",
    "print(f\"Fine-tuned Model Average:   {ft_wrong_avg:.3f}\")\n",
    "print(f\"Change:                     {wrong_delta:+.3f} ({wrong_pct:+.1f}%)\")\n",
    "print(\"(Lower is better - model should push wrong translations apart)\")\n",
    "print(\"\\nIndividual wrong pairs (orig -> finetuned):\")\n",
    "for (a, b), o, f in zip(wrong_translations, orig_wrong, ft_wrong):\n",
    "    d = f - o\n",
    "    pct = (d / o * 100) if o > 0 else 0\n",
    "    status = \"BETTER\" if f < o else \"WORSE\" if f > o else \"SAME\"\n",
    "    print(f\"  {status} | {o:.3f} -> {f:.3f} ({d:+.3f}, {pct:+.1f}%) | {a[:40]}... vs {b[:40]}...\")\n",
    "\n",
    "\n",
    "print(\"SUMMARY\")\n",
    "\n",
    "print(f\"Correct translations: {orig_trans_avg:.3f} -> {ft_trans_avg:.3f} ({delta:+.3f}, {pct:+.1f}%)\")\n",
    "print(f\"Wrong translations:   {orig_wrong_avg:.3f} -> {ft_wrong_avg:.3f} ({wrong_delta:+.3f}, {wrong_pct:+.1f}%)\")\n",
    "print(f\"\\nGap (correct - wrong): Original: {orig_trans_avg - orig_wrong_avg:.3f}, Fine-tuned: {ft_trans_avg - ft_wrong_avg:.3f}\")\n",
    "gap_improvement = (ft_trans_avg - ft_wrong_avg) - (orig_trans_avg - orig_wrong_avg)\n",
    "print(f\"Gap improvement: {gap_improvement:+.3f} (larger gap = better discrimination)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hw1DL)",
   "language": "python",
   "name": "hw1dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
