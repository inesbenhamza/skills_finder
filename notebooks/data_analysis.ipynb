{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "import numpy as np\n",
    "#os.listdir(\"data\")\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/notebooks\n",
      "Method 1: Found project root (from notebooks dir): /Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13\n",
      "‚úÖ Added project root to path: /Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13\n",
      "‚úÖ Verified helpers directory exists: True\n",
      "‚úÖ You can now import: from helpers.SkillsEmbeddings import ...\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Add project root to Python path for imports\n",
    "# Get the absolute path to the project root\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "# Try multiple methods to find project root\n",
    "project_root = None\n",
    "\n",
    "# Method 1: If we're in notebooks directory, go up one level\n",
    "if os.path.basename(current_dir) == 'notebooks':\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "    print(f\"Method 1: Found project root (from notebooks dir): {project_root}\")\n",
    "else:\n",
    "    # Method 2: Check if helpers directory exists in current or parent\n",
    "    if os.path.exists(os.path.join(current_dir, 'helpers')):\n",
    "        project_root = current_dir\n",
    "        print(f\"Method 2: Found project root (helpers in current dir): {project_root}\")\n",
    "    elif os.path.exists(os.path.join(os.path.dirname(current_dir), 'helpers')):\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "        print(f\"Method 3: Found project root (helpers in parent dir): {project_root}\")\n",
    "    else:\n",
    "        # Method 4: Try going up from current directory\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "        if os.path.exists(os.path.join(parent_dir, 'helpers')):\n",
    "            project_root = parent_dir\n",
    "            print(f\"Method 4: Found project root (going up one level): {project_root}\")\n",
    "        else:\n",
    "            # Method 5: Use absolute path - hardcode the known project path\n",
    "            # This is a fallback if all else fails\n",
    "            known_project_root = \"/Users/inesbenhamza/Downloads/SBI - √âquipe 1 (Team 1) 13\"\n",
    "            if os.path.exists(os.path.join(known_project_root, 'helpers')):\n",
    "                project_root = known_project_root\n",
    "                print(f\"Method 5: Using known absolute path: {project_root}\")\n",
    "\n",
    "# Verify helpers directory exists and add to path\n",
    "if project_root and os.path.exists(os.path.join(project_root, 'helpers')):\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "    print(f\"‚úÖ Added project root to path: {project_root}\")\n",
    "    print(f\"‚úÖ Verified helpers directory exists: {os.path.exists(os.path.join(project_root, 'helpers', 'SkillsEmbeddings.py'))}\")\n",
    "    print(f\"‚úÖ You can now import: from helpers.SkillsEmbeddings import ...\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: Could not find helpers directory. Project root: {project_root}\")\n",
    "    print(f\"‚ö†Ô∏è Current sys.path: {sys.path[:3]}\")  # Show first 3 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers\n",
    "#!pip install torch\n",
    "#!pip install numpy\n",
    "#!pip install scipy\n",
    "#!pip install pandas\n",
    "#!pip install pyyaml\n",
    "#!pip install streamlit\n",
    "#!pip install pymupdf\n",
    "#!pip install pdfplumber\n",
    "#!pip install anthropic\n",
    "#!pip install openai\n",
    "#!pip install google-generativeai\n",
    "#!pip install watchdog\n",
    "#!pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U sentence-transformers\n",
    "#!pip install pypdf\n",
    "#!pip install transformers\n",
    "#!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sentence_transformers import SentenceTransformer\n",
    "#from SkillsEmbeddings import SkillEmbeddingModel, save_skills_emb\n",
    "\n",
    "#model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "#skill_model = SkillEmbeddingModel(model)\n",
    "\n",
    "#save_skills_emb(\n",
    "    #input_csv=\"skills-finder-hackathon-hec-x-sbi/skillscleaned.csv\",\n",
    "    #output_npz=\"skills-finder-hackathon-hec-x-sbi/skills_encoded.npz\",\n",
    "    #model=skill_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading BGE-m3 model...\n",
      "üîÑ Initializing embedding wrapper...\n",
      "üîÑ Regenerating skills_encoded.npz with BGE-m3 embeddings...\n",
      "üìÅ Input CSV: /Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/skills-finder-hackathon-hec-x-sbi/skillscleaned.csv\n",
      "üìÅ Output NPZ: /Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/skills-finder-hackathon-hec-x-sbi/skills_encoded.npz\n",
      "‚úÖ DONE! New embeddings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from helpers.SkillsEmbeddings import SkillEmbeddingModel, save_skills_emb\n",
    "import os\n",
    "\n",
    "# Get project root (should be set in cell 1)\n",
    "# If not, detect it here\n",
    "if 'project_root' not in globals():\n",
    "    current_dir = os.getcwd()\n",
    "    if os.path.basename(current_dir) == 'notebooks':\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "else:\n",
    "    # Use the project_root from cell 1\n",
    "    pass\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "skill_model = SkillEmbeddingModel(model)\n",
    "\n",
    "\n",
    "# Use absolute paths based on project root\n",
    "input_csv = os.path.join(project_root, \"skills-finder-hackathon-hec-x-sbi\", \"skillscleaned.csv\")\n",
    "output_npz = os.path.join(project_root, \"skills-finder-hackathon-hec-x-sbi\", \"skills_encoded.npz\")\n",
    "\n",
    "print(f\"Input CSV: {input_csv}\")\n",
    "print(f\"Output NPZ: {output_npz}\")\n",
    "\n",
    "save_skills_emb(\n",
    "    input_csv=input_csv,\n",
    "    output_npz=output_npz,\n",
    "    model=skill_model\n",
    ")\n",
    "\n",
    "print(\"New embeddings saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting pdf text for encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "def extract_text(filename: str):\n",
    "    reader = PdfReader(filename)\n",
    "    complete_text = \"\"\n",
    "    # getting a specific page from the pdf file\n",
    "    for page in reader.pages:\n",
    "        complete_text += f\"\\n{page.extract_text()}\"\n",
    "    return complete_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HCK_HEC_LANG.csv', '.DS_Store', 'HCK_HEC_XP.csv', 'HCK_HEC_SKILLS.csv', 'HCK_HEC_USER.csv', 'HCK_HEC_STAFFING.csv', 'processed', 'raw']\n"
     ]
    }
   ],
   "source": [
    "# Get project root if not already set\n",
    "if 'project_root' not in globals():\n",
    "    current_dir = os.getcwd()\n",
    "    if os.path.basename(current_dir) == 'notebooks':\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "print(os.listdir(data_dir))\n",
    "# .DS_Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading all file at the same time not so useful "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning the lang dataset \n",
    "it contains the user IDs, the langauge and the skill level\n",
    "there are some NAs values that we replace by -1 (need to check why we did that in the first place)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = pd.read_csv(\"/Users/inesbenhamza/Downloads/skills-finder-hackathon-hec-x-sbi/HCK_HEC_LANG.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique id \n",
    "csvfile['USER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USER_ID LANGUAGE_SKILL_DSC  LANGUAGE_SKILL_LVL\n",
      "38   2433141             French               100.0\n",
      "102  2433141            English               100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(8)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(csvfile[csvfile['USER_ID']==2433141])\n",
    "csvfile['LANGUAGE_SKILL_LVL'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile['LANGUAGE_SKILL_LVL'] = csvfile['LANGUAGE_SKILL_LVL'].fillna(-1) # to handle missing values we fill them with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile['LANGUAGE_SKILL_LVL'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking if there a re duplicated rows \n",
    "print(csvfile.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = csvfile.groupby(['USER_ID', 'LANGUAGE_SKILL_DSC'])['LANGUAGE_SKILL_LVL'].idxmax()\n",
    "\n",
    "#idx = idx[idx.notna()]\n",
    "\n",
    "#df_filtered = csvfile.loc[idx]\n",
    "\n",
    "#df_filtered = df_filtered.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USER_ID LANGUAGE_SKILL_DSC  LANGUAGE_SKILL_LVL\n",
      "0  2432194            English               100.0\n",
      "1  2432194             French               100.0\n",
      "2  2433083            English                80.0\n",
      "3  2433083             French               100.0\n",
      "4  2433092            English                80.0\n",
      "5  2433092             French               100.0\n",
      "6  2433099            English                80.0\n",
      "7  2433099             French               100.0\n",
      "8  2433109            English                80.0\n",
      "9  2433109             French               100.0\n"
     ]
    }
   ],
   "source": [
    "df_filtered = csvfile.loc[csvfile.groupby(['USER_ID', 'LANGUAGE_SKILL_DSC'])['LANGUAGE_SKILL_LVL'].idxmax()]\n",
    " \n",
    "# Reset index if needed\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "print(df_filtered.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LANGUAGE_SKILL_DSC</th>\n",
       "      <th>LANGUAGE_SKILL_LVL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2664664</td>\n",
       "      <td>English</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2664664</td>\n",
       "      <td>French</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LANGUAGE_SKILL_DSC  LANGUAGE_SKILL_LVL\n",
       "170  2664664            English                -1.0\n",
       "171  2664664             French                -1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[df_filtered['USER_ID'] == 2664664]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print (df_filtered.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# storing lang clean into a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"langcleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a consultant_profile_df by merging all csv ( should we creat col skills 1, skills 2 etc ? or skilss : skills1,skills2 etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gettign workign directory \n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USER_ID LAST_NAME FIRST_NAME  ANNEES_XP\n",
      "0  2843838     Ramos      David        1.0\n",
      "1  2479537     Small       Carl        2.5\n",
      "2  2533337     Evans     Carmen        2.0\n",
      "3  2446382   Pittman     Brandi        2.5\n",
      "4  2433124    Thomas      Julie        2.5\n"
     ]
    }
   ],
   "source": [
    "expyears  = pd.read_csv(\"/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/data/HCK_HEC_USER.csv\")\n",
    "expyears['USER_ID'].nunique()\n",
    "\n",
    "print(expyears.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USer an dtheir name + experience in year is clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [USER_ID, LAST_NAME, FIRST_NAME, ANNEES_XP]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(expyears.duplicated().sum())\n",
    "# print if there is user id that are duplicated \n",
    "print(expyears[expyears.duplicated(subset=['USER_ID'], keep=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>SKILLS_DSC</th>\n",
       "      <th>DOMAIN_DSC</th>\n",
       "      <th>LEVEL_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2433083</td>\n",
       "      <td>DBT</td>\n",
       "      <td>Data Integration</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Analytics Platform System (SSAS)</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Azure Data Factory</td>\n",
       "      <td>Data Integration</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Azure Data Lake Store</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433083</td>\n",
       "      <td>Microsoft Azure SQL Database</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2978961</td>\n",
       "      <td>Snowflake Data Cloud</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2978961</td>\n",
       "      <td>Tableau Desktop and Online</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>3072774</td>\n",
       "      <td>Python</td>\n",
       "      <td>Programming Language</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>3072774</td>\n",
       "      <td>R</td>\n",
       "      <td>Programming Language</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>3072774</td>\n",
       "      <td>SQL</td>\n",
       "      <td>Programming Language</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID                                  SKILLS_DSC  \\\n",
       "0    2433083                                         DBT   \n",
       "1    2433083  Microsoft Analytics Platform System (SSAS)   \n",
       "2    2433083                Microsoft Azure Data Factory   \n",
       "3    2433083             Microsoft Azure Data Lake Store   \n",
       "4    2433083                Microsoft Azure SQL Database   \n",
       "..       ...                                         ...   \n",
       "979  2978961                        Snowflake Data Cloud   \n",
       "980  2978961                  Tableau Desktop and Online   \n",
       "981  3072774                                      Python   \n",
       "982  3072774                                           R   \n",
       "983  3072774                                         SQL   \n",
       "\n",
       "               DOMAIN_DSC  LEVEL_VAL  \n",
       "0        Data Integration       80.0  \n",
       "1         Data Management       80.0  \n",
       "2        Data Integration      100.0  \n",
       "3         Data Management       90.0  \n",
       "4         Data Management       90.0  \n",
       "..                    ...        ...  \n",
       "979       Data Management        0.0  \n",
       "980        Data Analytics        0.0  \n",
       "981  Programming Language       40.0  \n",
       "982  Programming Language       40.0  \n",
       "983  Programming Language       50.0  \n",
       "\n",
       "[984 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skillsclean = pd.read_csv(\"/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/data/raw/skillscleaned.csv\")\n",
    "\n",
    "skillsclean\n",
    "#print(print(skillsclean[skillsclean.duplicated(subset=['USER_ID'], keep=True)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Integration', 'Data Management', 'Agile Delivery',\n",
       "       'Financial Close', 'Data Analytics', 'Programming Language',\n",
       "       'Data Platform', 'Data Governance', 'Data Science',\n",
       "       'Financial Planning and Analysis'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skillsclean['DOMAIN_DSC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skillsclean['USER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skills_df = skillsclean  \n",
    "\n",
    "# Pivot the table to create a domain-based skill dictionary per consultant\n",
    "pivoted_df = skills_df.pivot_table(\n",
    "    index='USER_ID',\n",
    "    columns='DOMAIN_DSC',\n",
    "    values='LEVEL_VAL',\n",
    "    aggfunc=lambda x: dict(zip(skills_df.loc[x.index, 'SKILLS_DSC'], x))\n",
    ")\n",
    "\n",
    "# Reset index so USER_ID becomes a column\n",
    "pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "# Display result\n",
    "pivoted_df\n",
    "\n",
    "pivoted_df.to_csv(\"skills_pivoted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMAIN_DSC  USER_ID                                     Agile Delivery  \\\n",
      "0           2433083                                                NaN   \n",
      "1           2433092  {'Atlassian JIRA Software': 100.0, 'Microsoft ...   \n",
      "2           2433099  {'Atlassian JIRA Software': 80.0, 'Microsoft A...   \n",
      "3           2433109  {'Atlassian JIRA Software': 100.0, 'Microsoft ...   \n",
      "4           2433111                                                NaN   \n",
      "\n",
      "DOMAIN_DSC                                     Data Analytics Data Governance  \\\n",
      "0                                                         NaN             NaN   \n",
      "1                                                         NaN             NaN   \n",
      "2                            {'SAP BusinessObjects BI': 20.0}             NaN   \n",
      "3                                                         NaN             NaN   \n",
      "4           {'Microsoft Power BI': 80.0, 'Tableau Desktop ...             NaN   \n",
      "\n",
      "DOMAIN_DSC                                   Data Integration  \\\n",
      "0           {'DBT': 80.0, 'Microsoft Azure Data Factory': ...   \n",
      "1                                                         NaN   \n",
      "2                                                         NaN   \n",
      "3           {'Informatica PowerCenter': 100.0, 'Matillion ...   \n",
      "4                                                         NaN   \n",
      "\n",
      "DOMAIN_DSC                                    Data Management Data Platform  \\\n",
      "0           {'Microsoft Analytics Platform System (SSAS)':...           NaN   \n",
      "1                                                         NaN           NaN   \n",
      "2           {'SAP BW': 90.0, 'SAP BW/4HANA': 70.0, 'SAP HA...           NaN   \n",
      "3           {'Google BigQuery': 100.0, 'IBM Db2': 100.0, '...           NaN   \n",
      "4           {'Microsoft SQL Server': 80.0, 'Snowflake Data...           NaN   \n",
      "\n",
      "DOMAIN_DSC Data Science                                    Financial Close  \\\n",
      "0                   NaN                                                NaN   \n",
      "1                   NaN                                                NaN   \n",
      "2                   NaN  {'SAP Business Planning and Consolidation (SAP...   \n",
      "3                   NaN                                                NaN   \n",
      "4                   NaN                                                NaN   \n",
      "\n",
      "DOMAIN_DSC Financial Planning and Analysis  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      NaN   \n",
      "4                                      NaN   \n",
      "\n",
      "DOMAIN_DSC                               Programming Language  \n",
      "0                                                         NaN  \n",
      "1                                                         NaN  \n",
      "2                                                         NaN  \n",
      "3           {'DAX': 100.0, 'MDX': 100.0, 'SQL': 100.0, 'T-...  \n",
      "4                                 {'DAX': 70.0, 'SQL': 100.0}  \n"
     ]
    }
   ],
   "source": [
    "print(pivoted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging\n",
    "with availibility \n",
    "expereince \n",
    "mission \n",
    "lang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['USER_ID', 'Agile Delivery', 'Data Analytics', 'Data Governance',\n",
      "       'Data Integration', 'Data Management', 'Data Platform', 'Data Science',\n",
      "       'Financial Close', 'Financial Planning and Analysis',\n",
      "       'Programming Language'],\n",
      "      dtype='object', name='DOMAIN_DSC')\n"
     ]
    }
   ],
   "source": [
    "# checking the col \n",
    "pivoted_df\n",
    "print(pivoted_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#left merge to keep all rows from expyears \n",
    "\n",
    "fulldf = expyears.merge(pivoted_df, on=\"USER_ID\", how=\"left\")\n",
    "fulldf['USER_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df with user id, experience so ( USER) and SKILLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>Data Science</th>\n",
       "      <th>Financial Close</th>\n",
       "      <th>Financial Planning and Analysis</th>\n",
       "      <th>Programming Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Java': 70.0, 'Javascript': 20.0, 'PL/SQL': 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Hyperion Financial Management (HFM)':...</td>\n",
       "      <td>{'Applied OLAP Dodeca': 80.0, 'Oracle Cloud EP...</td>\n",
       "      <td>{'Java': 60.0, 'VBA': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Anaconda Enterprise': 0.0, 'Matlab': 0.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Cognos TM1': 10.0}</td>\n",
       "      <td>{'DAX': 20.0, 'Java': 20.0, 'Python': 40.0, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Java': 40.0, 'Python': 60.0, 'R': 40.0, 'SQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'CCH Tagetik CPM Conso': 60.0, 'Oracle Hyperi...</td>\n",
       "      <td>{'CCH Tagetik CPM Planning': 80.0, 'Oracle Hyp...</td>\n",
       "      <td>{'Java': 50.0, 'Python': 40.0, 'R': 40.0, 'SQL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Java': 30.0, 'Python': 70.0, 'SQL': 80.0, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                    Data Science  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2    {'Anaconda Enterprise': 0.0, 'Matlab': 0.0}   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "..                                           ...   \n",
       "114                                          NaN   \n",
       "115                                          NaN   \n",
       "116                                          NaN   \n",
       "117                                          NaN   \n",
       "118                                          NaN   \n",
       "\n",
       "                                       Financial Close  \\\n",
       "0                                                  NaN   \n",
       "1    {'Oracle Hyperion Financial Management (HFM)':...   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'CCH Tagetik CPM Conso': 60.0, 'Oracle Hyperi...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                       Financial Planning and Analysis  \\\n",
       "0                                                  NaN   \n",
       "1    {'Applied OLAP Dodeca': 80.0, 'Oracle Cloud EP...   \n",
       "2                             {'IBM Cognos TM1': 10.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'CCH Tagetik CPM Planning': 80.0, 'Oracle Hyp...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                  Programming Language  \n",
       "0    {'Java': 70.0, 'Javascript': 20.0, 'PL/SQL': 5...  \n",
       "1                         {'Java': 60.0, 'VBA': 100.0}  \n",
       "2    {'DAX': 20.0, 'Java': 20.0, 'Python': 40.0, 'S...  \n",
       "3    {'Java': 40.0, 'Python': 60.0, 'R': 40.0, 'SQL...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "114                                                NaN  \n",
       "115  {'Java': 50.0, 'Python': 40.0, 'R': 40.0, 'SQL...  \n",
       "116                                                NaN  \n",
       "117  {'Java': 30.0, 'Python': 70.0, 'SQL': 80.0, 'S...  \n",
       "118                                                NaN  \n",
       "\n",
       "[119 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availibility= pd.read_csv('/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/data/HCK_HEC_STAFFING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = fulldf.merge(availibility, on=\"USER_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_3</th>\n",
       "      <th>MONTH_4</th>\n",
       "      <th>MONTH_5</th>\n",
       "      <th>MONTH_6</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  ... MONTH_3 MONTH_4  \\\n",
       "0                                                  NaN  ...     100     100   \n",
       "1                                                  NaN  ...     100     100   \n",
       "2                                                  NaN  ...      25      25   \n",
       "3                                                  NaN  ...      25      25   \n",
       "4                                                  NaN  ...      25      25   \n",
       "..                                                 ...  ...     ...     ...   \n",
       "114                                                NaN  ...      25      25   \n",
       "115                                                NaN  ...       0       0   \n",
       "116                                                NaN  ...       0      25   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...  ...      25      25   \n",
       "118                                                NaN  ...      50      50   \n",
       "\n",
       "    MONTH_5 MONTH_6  MONTH_7  MONTH_8  MONTH_9  MONTH_10  MONTH_11  MONTH_12  \n",
       "0       100     100      100      100      100       100       100       100  \n",
       "1       100     100      100      100      100       100       100       100  \n",
       "2        25      25       25       25       25        25        25        25  \n",
       "3        25      25       25       25       50        25        25        25  \n",
       "4        25      25       50       25       25        25        25        25  \n",
       "..      ...     ...      ...      ...      ...       ...       ...       ...  \n",
       "114      25      25       25       25       25        25        25        25  \n",
       "115       0       0        0        0        0         0         0         0  \n",
       "116       0       0        0        0        0         0         0         0  \n",
       "117      25      25       25       50       25        25        25        25  \n",
       "118      50      25       50       50       50        50        50        50  \n",
       "\n",
       "[119 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for lang and mission multiple col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/wz4hfzq14nggvhjg7kkdsts80000gn/T/ipykernel_57208/1720805847.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lang_profiles = langskills.groupby(\"USER_ID\").apply(\n"
     ]
    }
   ],
   "source": [
    "langskills = pd.read_csv ('/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/langcleaned.csv')\n",
    "\n",
    "# Group by USER_ID and build dict of LANG: LEVEL\n",
    "lang_profiles = langskills.groupby(\"USER_ID\").apply(\n",
    "    lambda x: dict(zip(x[\"LANGUAGE_SKILL_DSC\"], x[\"LANGUAGE_SKILL_LVL\"]))\n",
    ").reset_index(name=\"LANGUAGE_PROFILE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_4</th>\n",
       "      <th>MONTH_5</th>\n",
       "      <th>MONTH_6</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "      <th>LANGUAGE_PROFILE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 90.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 50.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 60.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 80.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 80.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 70.0, 'French': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'English': 80.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  ... MONTH_4 MONTH_5  \\\n",
       "0                                                  NaN  ...     100     100   \n",
       "1                                                  NaN  ...     100     100   \n",
       "2                                                  NaN  ...      25      25   \n",
       "3                                                  NaN  ...      25      25   \n",
       "4                                                  NaN  ...      25      25   \n",
       "..                                                 ...  ...     ...     ...   \n",
       "114                                                NaN  ...      25      25   \n",
       "115                                                NaN  ...       0       0   \n",
       "116                                                NaN  ...      25       0   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...  ...      25      25   \n",
       "118                                                NaN  ...      50      50   \n",
       "\n",
       "    MONTH_6 MONTH_7  MONTH_8  MONTH_9  MONTH_10  MONTH_11  MONTH_12  \\\n",
       "0       100     100      100      100       100       100       100   \n",
       "1       100     100      100      100       100       100       100   \n",
       "2        25      25       25       25        25        25        25   \n",
       "3        25      25       25       50        25        25        25   \n",
       "4        25      50       25       25        25        25        25   \n",
       "..      ...     ...      ...      ...       ...       ...       ...   \n",
       "114      25      25       25       25        25        25        25   \n",
       "115       0       0        0        0         0         0         0   \n",
       "116       0       0        0        0         0         0         0   \n",
       "117      25      25       50       25        25        25        25   \n",
       "118      25      50       50       50        50        50        50   \n",
       "\n",
       "                        LANGUAGE_PROFILE  \n",
       "0    {'English': 100.0, 'French': 100.0}  \n",
       "1     {'English': 90.0, 'French': 100.0}  \n",
       "2     {'English': 50.0, 'French': 100.0}  \n",
       "3     {'English': 60.0, 'French': 100.0}  \n",
       "4    {'English': 100.0, 'French': 100.0}  \n",
       "..                                   ...  \n",
       "114   {'English': 100.0, 'French': 80.0}  \n",
       "115  {'English': 100.0, 'French': 100.0}  \n",
       "116   {'English': 80.0, 'French': 100.0}  \n",
       "117   {'English': 70.0, 'French': 100.0}  \n",
       "118                    {'English': 80.0}  \n",
       "\n",
       "[119 rows x 27 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf = fulldf.merge(lang_profiles, on=\"USER_ID\", how=\"left\")\n",
    "\n",
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission = pd.read_csv('/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/data/HCK_HEC_XP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we gorup mission by user so that it become \n",
    "USER_ID\tMISSIONS_LIST\n",
    "2843838\t[mission1, mission2, mission3, ‚Ä¶]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     USER_ID                                      MISSIONS_LIST  \\\n",
      "0    2432194  [Analyse de la situation actuelle et d√©finitio...   \n",
      "1    2433083  [Exhaustive data analysis, Translation of the ...   \n",
      "2    2433092  [Gestion du budget., Planification de l'√©ch√©an...   \n",
      "3    2433099  [Faire le suivi des activit√©s de configuration...   \n",
      "4    2433109  [Understanding of customer requirements, Analy...   \n",
      "..       ...                                                ...   \n",
      "109  2957009  [Collaborate with stakeholders, users, and dev...   \n",
      "110  2976032  [*      Coordination with different team membe...   \n",
      "111  2977311  [Increased product KPIs  by implementing a use...   \n",
      "112  2978961  [Interface entre les utilisateurs finaux / par...   \n",
      "113  3072774  [- Restructuration of the Centers Of Excellenc...   \n",
      "\n",
      "                                         MISSIONS_TEXT  \n",
      "0    Analyse de la situation actuelle et d√©finition...  \n",
      "1    Exhaustive data analysis Translation of the bu...  \n",
      "2    Gestion du budget. Planification de l'√©ch√©anci...  \n",
      "3    Faire le suivi des activit√©s de configuration ...  \n",
      "4    Understanding of customer requirements Analysi...  \n",
      "..                                                 ...  \n",
      "109  Collaborate with stakeholders, users, and deve...  \n",
      "110  *      Coordination with different team member...  \n",
      "111  Increased product KPIs  by implementing a user...  \n",
      "112  Interface entre les utilisateurs finaux / part...  \n",
      "113  - Restructuration of the Centers Of Excellence...  \n",
      "\n",
      "[114 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missions_grouped = mission.groupby(\"USER_ID\")[\"MISSION_DSC\"].apply(list).reset_index(name=\"MISSIONS_LIST\")\n",
    "\n",
    "\n",
    "missions_grouped[\"MISSIONS_TEXT\"] = missions_grouped[\"MISSIONS_LIST\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print (missions_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = fulldf.merge(missions_grouped, on=\"USER_ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>ANNEES_XP</th>\n",
       "      <th>Agile Delivery</th>\n",
       "      <th>Data Analytics</th>\n",
       "      <th>Data Governance</th>\n",
       "      <th>Data Integration</th>\n",
       "      <th>Data Management</th>\n",
       "      <th>Data Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_6</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "      <th>LANGUAGE_PROFILE</th>\n",
       "      <th>MISSIONS_LIST</th>\n",
       "      <th>MISSIONS_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843838</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>David</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "      <td>[Mise en place d‚Äôun pipeline RAG pour la migra...</td>\n",
       "      <td>Mise en place d‚Äôun pipeline RAG pour la migrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479537</td>\n",
       "      <td>Small</td>\n",
       "      <td>Carl</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Oracle Analytics Cloud': 60.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'English': 90.0, 'French': 100.0}</td>\n",
       "      <td>[Mise en ≈ìuvre d‚Äôune application de simulation...</td>\n",
       "      <td>Mise en ≈ìuvre d‚Äôune application de simulation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533337</td>\n",
       "      <td>Evans</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'GitLab': 40.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Talend Open Studio for Data Quality': 20.0}</td>\n",
       "      <td>{'Oracle Data Integrator (ODI)': 30.0, 'Talend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 50.0, 'French': 100.0}</td>\n",
       "      <td>[Int√©gration de donn√©es, Analyser et r√©soudre ...</td>\n",
       "      <td>Int√©gration de donn√©es Analyser et r√©soudre le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2446382</td>\n",
       "      <td>Pittman</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft Power BI': 80.0, 'Microsoft SQL Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Microsoft SQL Server Integration Services (S...</td>\n",
       "      <td>{'Microsoft Analytics Platform System (SSAS)':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 60.0, 'French': 100.0}</td>\n",
       "      <td>[Analyser le syst√®me d'information financier, ...</td>\n",
       "      <td>Analyser le syst√®me d'information financier Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2433124</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Snowflake Data Cloud': 100.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "      <td>[Restitution et transmission des connaissances...</td>\n",
       "      <td>Restitution et transmission des connaissances ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2713733</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 100.0, 'French': 80.0}</td>\n",
       "      <td>[Support aux utilisateurs finaux de niveau 2, ...</td>\n",
       "      <td>Support aux utilisateurs finaux de niveau 2 Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2456947</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>Karen</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'IBM Db2': 80.0, 'Microsoft Analytics Platfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 100.0, 'French': 100.0}</td>\n",
       "      <td>[Analyses des fichiers Excel utilis√©s pour aut...</td>\n",
       "      <td>Analyses des fichiers Excel utilis√©s pour auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2447672</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>Diana</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'English': 80.0, 'French': 100.0}</td>\n",
       "      <td>[**Business Analyst for the implementation of ...</td>\n",
       "      <td>**Business Analyst for the implementation of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2789547</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Brian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Atlassian JIRA Software': 80.0, 'Terraform':...</td>\n",
       "      <td>{'Microsoft Power BI': 80.0}</td>\n",
       "      <td>{'Azure Purview': 60.0}</td>\n",
       "      <td>{'Microsoft Azure Data Factory': 80.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Databricks Lakehouse Platform': 80.0, 'Googl...</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'English': 70.0, 'French': 100.0}</td>\n",
       "      <td>[Design and implementation of data architectur...</td>\n",
       "      <td>Design and implementation of data architecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2920938</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'English': 80.0}</td>\n",
       "      <td>[Atelier de travail avec le [CLIENT] pour comp...</td>\n",
       "      <td>Atelier de travail avec le [CLIENT] pour compr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID LAST_NAME FIRST_NAME  ANNEES_XP  \\\n",
       "0    2843838     Ramos      David        1.0   \n",
       "1    2479537     Small       Carl        2.5   \n",
       "2    2533337     Evans     Carmen        2.0   \n",
       "3    2446382   Pittman     Brandi        2.5   \n",
       "4    2433124    Thomas      Julie        2.5   \n",
       "..       ...       ...        ...        ...   \n",
       "114  2713733  Williams    Raymond        1.5   \n",
       "115  2456947    Riddle      Karen        2.5   \n",
       "116  2447672  Gonzalez      Diana        2.5   \n",
       "117  2789547  Williams      Brian        1.0   \n",
       "118  2920938  Martinez      Nancy        0.5   \n",
       "\n",
       "                                        Agile Delivery  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                     {'GitLab': 40.0}   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117  {'Atlassian JIRA Software': 80.0, 'Terraform':...   \n",
       "118                                                NaN   \n",
       "\n",
       "                                        Data Analytics  \\\n",
       "0                                                  NaN   \n",
       "1                     {'Oracle Analytics Cloud': 60.0}   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Power BI': 80.0, 'Microsoft SQL Se...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                       {'Microsoft Power BI': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                   Data Governance  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2    {'Talend Open Studio for Data Quality': 20.0}   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "..                                             ...   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                        {'Azure Purview': 60.0}   \n",
       "118                                            NaN   \n",
       "\n",
       "                                      Data Integration  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    {'Oracle Data Integrator (ODI)': 30.0, 'Talend...   \n",
       "3    {'Microsoft SQL Server Integration Services (S...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117             {'Microsoft Azure Data Factory': 80.0}   \n",
       "118                                                NaN   \n",
       "\n",
       "                                       Data Management  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    {'Microsoft Analytics Platform System (SSAS)':...   \n",
       "4                      {'Snowflake Data Cloud': 100.0}   \n",
       "..                                                 ...   \n",
       "114                                                NaN   \n",
       "115  {'IBM Db2': 80.0, 'Microsoft Analytics Platfor...   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "\n",
       "                                         Data Platform  ... MONTH_6 MONTH_7  \\\n",
       "0                                                  NaN  ...     100     100   \n",
       "1                                                  NaN  ...     100     100   \n",
       "2                                                  NaN  ...      25      25   \n",
       "3                                                  NaN  ...      25      25   \n",
       "4                                                  NaN  ...      25      50   \n",
       "..                                                 ...  ...     ...     ...   \n",
       "114                                                NaN  ...      25      25   \n",
       "115                                                NaN  ...       0       0   \n",
       "116                                                NaN  ...       0       0   \n",
       "117  {'Databricks Lakehouse Platform': 80.0, 'Googl...  ...      25      25   \n",
       "118                                                NaN  ...      25      50   \n",
       "\n",
       "    MONTH_8 MONTH_9  MONTH_10  MONTH_11  MONTH_12  \\\n",
       "0       100     100       100       100       100   \n",
       "1       100     100       100       100       100   \n",
       "2        25      25        25        25        25   \n",
       "3        25      50        25        25        25   \n",
       "4        25      25        25        25        25   \n",
       "..      ...     ...       ...       ...       ...   \n",
       "114      25      25        25        25        25   \n",
       "115       0       0         0         0         0   \n",
       "116       0       0         0         0         0   \n",
       "117      50      25        25        25        25   \n",
       "118      50      50        50        50        50   \n",
       "\n",
       "                        LANGUAGE_PROFILE  \\\n",
       "0    {'English': 100.0, 'French': 100.0}   \n",
       "1     {'English': 90.0, 'French': 100.0}   \n",
       "2     {'English': 50.0, 'French': 100.0}   \n",
       "3     {'English': 60.0, 'French': 100.0}   \n",
       "4    {'English': 100.0, 'French': 100.0}   \n",
       "..                                   ...   \n",
       "114   {'English': 100.0, 'French': 80.0}   \n",
       "115  {'English': 100.0, 'French': 100.0}   \n",
       "116   {'English': 80.0, 'French': 100.0}   \n",
       "117   {'English': 70.0, 'French': 100.0}   \n",
       "118                    {'English': 80.0}   \n",
       "\n",
       "                                         MISSIONS_LIST  \\\n",
       "0    [Mise en place d‚Äôun pipeline RAG pour la migra...   \n",
       "1    [Mise en ≈ìuvre d‚Äôune application de simulation...   \n",
       "2    [Int√©gration de donn√©es, Analyser et r√©soudre ...   \n",
       "3    [Analyser le syst√®me d'information financier, ...   \n",
       "4    [Restitution et transmission des connaissances...   \n",
       "..                                                 ...   \n",
       "114  [Support aux utilisateurs finaux de niveau 2, ...   \n",
       "115  [Analyses des fichiers Excel utilis√©s pour aut...   \n",
       "116  [**Business Analyst for the implementation of ...   \n",
       "117  [Design and implementation of data architectur...   \n",
       "118  [Atelier de travail avec le [CLIENT] pour comp...   \n",
       "\n",
       "                                         MISSIONS_TEXT  \n",
       "0    Mise en place d‚Äôun pipeline RAG pour la migrat...  \n",
       "1    Mise en ≈ìuvre d‚Äôune application de simulation ...  \n",
       "2    Int√©gration de donn√©es Analyser et r√©soudre le...  \n",
       "3    Analyser le syst√®me d'information financier Co...  \n",
       "4    Restitution et transmission des connaissances ...  \n",
       "..                                                 ...  \n",
       "114  Support aux utilisateurs finaux de niveau 2 Pr...  \n",
       "115  Analyses des fichiers Excel utilis√©s pour auto...  \n",
       "116  **Business Analyst for the implementation of a...  \n",
       "117  Design and implementation of data architecture...  \n",
       "118  Atelier de travail avec le [CLIENT] pour compr...  \n",
       "\n",
       "[119 rows x 29 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.to_csv(\"full_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "print(fulldf['USER_ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP / Similarity : Utiliser des embeddings (e.g. SentenceTransformer) pour comparer missions pass√©es aux responsabilit√©s du mandat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3277907371520996\n",
      "0.15160588920116425\n",
      "0.7804136276245117\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "\n",
    "    embeddings1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(text2, convert_to_tensor=True)\n",
    "\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores.item()\n",
    "\n",
    "\n",
    "text1 = \"Created various Customized and interactive Reports and Dashboards in Power BI.\"\n",
    "text2 = \"developement de dashboard sur Power BI\"\n",
    "text3 = \"J'aime courir\"\n",
    "text4 = \"Mettre en place un flux de donn√©es depuis un ERP vers une database Snowflake\"\n",
    "text5 = \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps (CI/CD, versioning, rollback).\"\n",
    "text6 = \"impl√©menter un pipeline d‚Äôint√©gration de donn√©es entre un syst√®me ERP et une base de donn√©es Snowflake\"\n",
    "#compute_similarity(text3, text1)\n",
    "#compute_similarity(text3, text2)\n",
    "print(compute_similarity(text1, text6))\n",
    "print(compute_similarity(text1, text3))\n",
    "print(compute_similarity(text1, text2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3277907371520996\n",
      "0.15160588920116425\n",
      "0.7804136276245117\n"
     ]
    }
   ],
   "source": [
    "print(compute_similarity(text1, text6))\n",
    "print(compute_similarity(text1, text3))\n",
    "print(compute_similarity(text1, text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine tuning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data engineer responsabilit√© \n",
    "  - \"Concevoir et d√©velopper des pipelines d'ingestion de donn√©es robustes et optimis√©s √† l'aide d'Azure Data Factory\"\n",
    "  - \"D√©velopper des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"\n",
    "  - \"Impl√©menter des flux de donn√©es streaming et batch via Databricks Streaming et Apache Kafka\"\n",
    "  - \"Participer √† la d√©finition et √† la mise en ≈ìuvre de mod√®les de donn√©es adapt√©s aux besoins analytiques\"\n",
    "  - \"Mettre en ≈ìuvre des processus de validation de la qualit√© des donn√©es\"\n",
    "  - \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps\"\n",
    "  - \"Documenter les solutions d√©velopp√©es selon les normes internes\"\n",
    "  - \"Travailler en collaboration avec les √©quipes Data Science, BI et IT Infrastructure\"\n",
    "  - \"Participer √† l‚Äô√©laboration des principes d‚Äôarchitecture data et de gouvernance des donn√©es\"\n",
    "\n",
    "  need to encode the data engineer reponsabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HCK_HEC_LANG.csv', '.DS_Store', 'HCK_HEC_XP.csv', 'HCK_HEC_SKILLS.csv', 'HCK_HEC_USER.csv', 'HCK_HEC_STAFFING.csv', 'processed', 'raw']\n"
     ]
    }
   ],
   "source": [
    "if 'project_root' not in globals():\n",
    "    current_dir = os.getcwd()\n",
    "    if os.path.basename(current_dir) == 'notebooks':\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "full_df = pd.read_csv(\n",
    "    os.path.join(project_root, \"full_df.csv\"),\n",
    "    sep=',', \n",
    "    on_bad_lines='skip', \n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    Reinforce and Develop brand awareness #FUNgeni...\n",
      "Name: MISSIONS_TEXT, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(full_df.loc[full_df[\"USER_ID\"] ==2475141, \"MISSIONS_TEXT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2843838,  2479537,  2533337,  2446382,  2433124,  2817191,\n",
       "        2936770,  2501258,  2433139,  2480827,  2433122,  2433125,\n",
       "        2513848,  2433130,  2447746,  2433144,  2433117,  2433135,\n",
       "        2475141,  2445183,  2671704,  2501164,  2451715,  2446130,\n",
       "        2452725,  2977311,  2583132,  2513866,  2443989,  2700124,\n",
       "        2836571,  2683916,  2978961,  2432194,  2453262,  2443199,\n",
       "        3072774,  2726335,  2433140,  2503861,  2433083,  2471586,\n",
       "        2578963,  2903451,  2766619,  2841644,  2708864,  2967233,\n",
       "        2446029,  2693756,  2513831,  2453233,  2552838,  2445156,\n",
       "        2433109,  2433142,  2437177,  2449548,  2450849,  2502347,\n",
       "        2645516,  2447527,  2433099,  2433118,  2433114,  2818577,\n",
       "        2634429,  2725267,  2433134,  2433120,  2664664,  2443208,\n",
       "        2456839,  2445149,  2451804,  2433141,  2540340,  2708468,\n",
       "        2447137,  2433111,  2444211,  2443771,  2599691,  2976032,\n",
       "        2433092,  2676328,  2689959,  2551856,  2433143,  2449781,\n",
       "        2501974,  2433136,  2579999,  2442934,  2433138,  2799951,\n",
       "        2433112,  2571584,  2433852,  2535513,  2946290,  2895177,\n",
       "        2662823,  2448418,  2457327,  2634865,  2445187,  2789583,\n",
       "        2451833,  2560995,  2957009,  2533338,  2499680,  2449639,\n",
       "        2713733,  2456947,  2447672,  2789547,  2920938, 29209381,\n",
       "       29209382, 29209383, 29209384, 29209385, 29209386, 29209387,\n",
       "       29209388, 29209389])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[\"USER_ID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[\"USER_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine tuning bert for paraphrase detection (are the two sentences paraphrases of each other?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 36 examples\n",
      "Positive pairs: 26, Negative pairs: 10\n",
      "Using ContrastiveLoss with margin=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/inesbenhamza/Downloads/SBI - EÃÅquipe 1 (Team 1) 13/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to modelfinetuned\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "positive_pairs = [\n",
    "    \n",
    "    (\"Built dashboards in Power BI\", \"Cr√©er des tableaux de bord Power BI\"),\n",
    "    (\"Created data pipelines using ADF\", \"Concevoir des pipelines d‚Äôingestion de donn√©es avec Azure Data Factory\"),\n",
    "\n",
    "    \n",
    "    (\"Design and develop robust and optimized data ingestion pipelines using Azure Data Factory\",\n",
    "     \"Concevoir et d√©velopper des pipelines d'ingestion de donn√©es robustes et optimis√©s √† l'aide d'Azure Data Factory\"),\n",
    "\n",
    "    (\"Develop complex transformations using Apache Spark (Scala/Python) in Azure Databricks\",\n",
    "     \"D√©velopper des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "\n",
    "    (\"Implement streaming and batch data flows via Databricks Streaming and Apache Kafka\",\n",
    "     \"Impl√©menter des flux de donn√©es streaming et batch via Databricks Streaming et Apache Kafka\"),\n",
    "\n",
    "    (\"Participate in defining and implementing data models adapted to analytical needs\",\n",
    "     \"Participer √† la d√©finition et √† la mise en ≈ìuvre de mod√®les de donn√©es adapt√©s aux besoins analytiques\"),\n",
    "\n",
    "    (\"Implement data quality validation processes\",\n",
    "     \"Mettre en ≈ìuvre des processus de validation de la qualit√© des donn√©es\"),\n",
    "\n",
    "    (\"Automate pipeline deployments and tests via Azure DevOps\",\n",
    "     \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps\"),\n",
    "\n",
    "    (\"Document developed solutions according to internal standards\",\n",
    "     \"Documenter les solutions d√©velopp√©es selon les normes internes\"),\n",
    "\n",
    "    (\"Collaborate with Data Science, BI, and IT Infrastructure teams\",\n",
    "     \"Travailler en collaboration avec les √©quipes Data Science, BI et IT Infrastructure\"),\n",
    "\n",
    "    (\"Contribute to the development of data architecture and data governance principles\",\n",
    "     \"Participer √† l'√©laboration des principes d'architecture data et de gouvernance des donn√©es\"),\n",
    "\n",
    "    (\"Facilitated Scrum ceremonies including planning and retrospectives\",\n",
    "     \"Faciliter l‚Äôensemble des c√©r√©monies Scrum\"),\n",
    "    (\"Acted as Agile coach for cross-functional team\",\n",
    "     \"Agir en tant que coach Agile\"),\n",
    "    (\"Helped Product Owner manage backlog and define priorities\",\n",
    "     \"Aider le Product Owner √† g√©rer efficacement le backlog produit\"),\n",
    "    (\"Tracked team velocity and analyzed sprint metrics\",\n",
    "     \"Mesurer et analyser la performance de l‚Äô√©quipe via des indicateurs cl√©s\"),\n",
    "    (\"Protected team from external distractions\",\n",
    "     \"Prot√©ger l‚Äô√©quipe des interf√©rences externes\"),\n",
    "\n",
    "    (\"Built dashboards in Power BI\",\n",
    "     \"D√©velopper des tableaux de bord et rapports dans Power BI\"),\n",
    "    (\"Wrote performant SQL queries to transform marketing data\",\n",
    "     \"R√©diger du code SQL performant\"),\n",
    "    (\"Performed data integration from CRM and Google Analytics\",\n",
    "     \"Int√©grer les donn√©es issues de diverses plateformes (Google Analytics, CRM...)\"),\n",
    "    (\"Collaborated with analysts to understand reporting needs\",\n",
    "     \"Collaborer √©troitement avec les analystes pour comprendre leurs besoins\"),\n",
    "    (\"Designed data models aligned with business goals\",\n",
    "     \"Concevoir des mod√®les de donn√©es adapt√©s aux objectifs m√©tiers\"),\n",
    "    (\"Facilitated Scrum ceremonies including planning and retrospectives\",\n",
    "     \"Faciliter l‚Äôensemble des c√©r√©monies Scrum\"),\n",
    "    (\"Acted as Agile coach for cross-functional team\",\n",
    "     \"Agir en tant que coach Agile\"),\n",
    "    (\"Helped Product Owner manage backlog and define priorities\",\n",
    "     \"Aider le Product Owner √† g√©rer efficacement le backlog produit\"),\n",
    "    (\"Tracked team velocity and analyzed sprint metrics\",\n",
    "     \"Mesurer et analyser la performance de l‚Äô√©quipe via des indicateurs cl√©s\"),\n",
    "    (\"Protected team from external distractions\",\n",
    "     \"Prot√©ger l‚Äô√©quipe des interf√©rences externes\"),\n",
    "]\n",
    "\n",
    "negative_pairs = [\n",
    "    (\"Built dashboards in Power BI\", \"Pr√©parer des repas en cuisine\"),\n",
    "    (\"Created REST APIs\", \"Aider les patients dans les soins\"),\n",
    "    (\"Collaborated with ML and BI teams\", \"Mesurer la performance de l‚Äô√©quipe via des burndown charts\"),\n",
    "    (\"Developed PySpark jobs\", \"Travailler avec des personas marketing pour la strat√©gie de contenu\"),\n",
    "    (\"Implemented Kafka streaming\", \"Cr√©er des affiches pour un √©v√©nement social\"),\n",
    "    (\"Automated deployment with Azure DevOps\", \"G√©rer les pr√©sences dans un club de sport\"),\n",
    "    (\"Helped define data architecture\", \"Traduire un document marketing en espagnol\"),\n",
    "    (\"Documented pipelines\", \"R√©diger une lettre de motivation\"),\n",
    "    (\"Assisted customers in retail\", \"Concevoir des mod√®les de donn√©es m√©tiers\"),\n",
    "    (\"Conducted financial audits\", \"Faciliter les c√©r√©monies Scrum\"),\n",
    "]\n",
    "\n",
    "train_examples = [\n",
    "    InputExample(texts=[text1, text2], label=1.0) for text1, text2 in positive_pairs\n",
    "] + [\n",
    "    InputExample(texts=[text1, text2], label=0.0) for text1, text2 in negative_pairs\n",
    "]\n",
    "\n",
    "# Improved training setup\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)  # Increased from 1\n",
    "\n",
    "# Use ContrastiveLoss instead of CosineSimilarityLoss for binary labels\n",
    "# ContrastiveLoss is designed for positive/negative pairs with margin-based learning\n",
    "train_loss = losses.ContrastiveLoss(\n",
    "    model,\n",
    "    distance_metric=losses.SiameseDistanceMetric.COSINE_DISTANCE,\n",
    "    margin=0.5  # Margin between positive and negative pairs\n",
    ")\n",
    "\n",
    "print(f\"Training with {len(train_examples)} examples\")\n",
    "print(f\"Positive pairs: {len(positive_pairs)}, Negative pairs: {len(negative_pairs)}\")\n",
    "print(f\"Using ContrastiveLoss with margin=0.5\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=5,  # Increased from 3\n",
    "    warmup_steps=100,  # Increased from 10\n",
    "    optimizer_params={'lr': 2e-5},  # Explicit learning rate\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "model.save(\"modelfinetuned\")\n",
    "print(\"‚úÖ Model saved to modelfinetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#import subprocess\n",
    "\n",
    "#subprocess.check_call([\n",
    "    #sys.executable, \"-m\", \"pip\", \"install\", \"accelerate>=0.26.0\"\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autre\n",
    "essaie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'modelfinetuned' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 43 examples\n",
      "Positive pairs: 28, Negative pairs: 15\n",
      "Using ContrastiveLoss with margin=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to modelfinetuned2\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = SentenceTransformer(\"modelfinetuned\")\n",
    "positive_pairs = [\n",
    "    (\"Built dashboards in Power BI\", \"Cr√©er des tableaux de bord Power BI\"),\n",
    "    (\"Created data pipelines using ADF\", \"Concevoir des pipelines d‚Äôingestion de donn√©es avec Azure Data Factory\"),\n",
    "    (\"Develop complex transformations using Apache Spark\", \"D√©velopper des transformations complexes avec Apache Spark\"),\n",
    "    (\"Developed PySpark jobs on Databricks\", \"Cr√©er des transformations complexes avec Spark dans Azure Databricks\"),\n",
    "    (\"Built CI/CD workflows using Azure DevOps\", \"Automatiser les d√©ploiements via Azure DevOps (CI/CD)\"),\n",
    "    (\"Designed a lakehouse architecture\", \"Participer √† l‚Äô√©laboration de l‚Äôarchitecture data\"),\n",
    "    (\"Monitored and maintained ADF pipelines in production\", \n",
    "     \"Assurer la qualit√© et la fiabilit√© des pipelines dans Azure Data Factory\"),\n",
    "    (\"Worked closely with stakeholders to define KPIs and dashboards\", \n",
    "     \"Collaborer avec les analystes pour concevoir des tableaux de bord m√©tier\"),\n",
    "    (\"Wrote optimized SQL for analytics reporting\", \n",
    "     \"R√©diger du code SQL performant pour l‚Äôanalyse de donn√©es\"),\n",
    "    (\"Helped PO with backlog prioritization\", \n",
    "     \"Aider le Product Owner √† g√©rer efficacement le backlog produit\"),\n",
    "    (\"Improved data quality checks in Spark pipelines\", \n",
    "     \"Mettre en ≈ìuvre des processus de validation de la qualit√© des donn√©es\"),\n",
    "    (\"Facilitated daily standups and retrospectives\", \n",
    "     \"Animer les c√©r√©monies Scrum (daily, r√©trospective, sprint planning)\"),\n",
    "    (\"Protected team focus from outside distractions\", \n",
    "     \"Prot√©ger l‚Äô√©quipe des interf√©rences externes\"),\n",
    "    (\"Worked with BI and data science to align reporting\", \n",
    "     \"Travailler en collaboration avec les √©quipes Data Science, BI et IT\"),\n",
    "\n",
    "\n",
    "\n",
    "    (\"Impl√©mentation et automatisation sur Azure Data Factory (ADF)\",\n",
    "     \"Concevoir et d√©velopper des pipelines d'ingestion de donn√©es robustes et optimis√©s √† l'aide d'Azure Data Factory\"),\n",
    "\n",
    "    (\"Utilisation de Synapse serverless et cr√©ation de workspace\",\n",
    "     \"D√©velopper des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "\n",
    "    (\"Cr√©ation de mod√®les de donn√©es en √©toile avec gestion des SCD2\",\n",
    "     \"Participer √† la d√©finition et √† la mise en ≈ìuvre de mod√®les de donn√©es adapt√©s aux besoins analytiques\"),\n",
    "\n",
    "    (\"Mise en place de Snowflake, gestion des droits, objets, dynamic tables\",\n",
    "     \"Contribuer √† l‚Äô√©laboration des principes d‚Äôarchitecture data et de gouvernance des donn√©es\"),\n",
    "\n",
    "    (\"Utilisation de Azure DevOps pour g√©rer les environnements\",\n",
    "     \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps\"),\n",
    "\n",
    "    (\"R√©alisation d‚Äôanalyses de performance sur Snowflake\",\n",
    "     \"Mettre en ≈ìuvre des processus de validation de la qualit√© des donn√©es\"),\n",
    "\n",
    "    (\"Facilitation des c√©r√©monies Agile (Daily, R√©tro, Planning)\",\n",
    "     \"Faciliter l‚Äôensemble des c√©r√©monies Scrum\"),\n",
    "\n",
    "    (\"Accompagnement des √©quipes pour adopter les pratiques Agile\",\n",
    "     \"Agir en tant que coach Agile\"),\n",
    "\n",
    "    (\"Soutien au Product Owner dans la priorisation du backlog\",\n",
    "     \"Aider le Product Owner √† g√©rer efficacement le backlog produit\"),\n",
    "\n",
    "    (\"Analyse des KPIs projet et am√©lioration continue\",\n",
    "     \"Mesurer et analyser la performance de l‚Äô√©quipe via des indicateurs cl√©s\"),\n",
    "\n",
    "    (\"Cr√©ation de rapports Power BI √† partir de sources SQL Server\",\n",
    "     \"D√©velopper des tableaux de bord et rapports dans Power BI\"),\n",
    "\n",
    "    (\"√âcriture de requ√™tes SQL complexes pour extraire des indicateurs cl√©s\",\n",
    "     \"R√©diger du code SQL performant\"),\n",
    "\n",
    "    (\"Int√©gration de donn√©es depuis des fichiers Excel et des syst√®mes externes\",\n",
    "     \"Int√©grer les donn√©es issues de diverses plateformes (Google Analytics, CRM...)\"),\n",
    "\n",
    "    (\"Collaboration avec les analystes pour d√©finir des rapports pertinents\",\n",
    "     \"Collaborer √©troitement avec les analystes pour comprendre leurs besoins\"),\n",
    "]\n",
    "\n",
    "negative_pairs = [\n",
    "\n",
    "    (\"Built dashboards in Power BI\", \"Pr√©parer des repas en cuisine\"),\n",
    "    (\"Created REST APIs\", \"Aider les patients dans les soins\"),\n",
    "\n",
    "   \n",
    "    (\"Collaborated with ML and BI teams\", \"Mesurer la performance de l‚Äô√©quipe via des burndown charts\"),\n",
    "    (\"Helped define data architecture\", \"Cr√©er des affiches pour un √©v√©nement social\"),\n",
    "    (\"Developed PySpark jobs\", \"Animer un atelier marketing\"),\n",
    "    (\"Implemented Kafka streaming\", \"Cr√©er du contenu pour les r√©seaux sociaux\"),\n",
    "    (\"Automated deployment with Azure DevOps\", \"G√©rer les pr√©sences dans un club de sport\"),\n",
    "    (\"Documented pipelines\", \"Traduire un document marketing\"),\n",
    "    (\"Designed KPI dashboards\", \"Agir en tant que coach Agile (Scrum Master)\"),\n",
    "    (\"Helped organize hackathon logistics\", \"Construire des pipelines avec Apache Spark\"),\n",
    "    (\"Cr√©ation de dashboards dans Power BI\",\n",
    "     \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps\"),\n",
    "    (\"Faciliter les c√©r√©monies Scrum\",\n",
    "     \"D√©velopper des transformations complexes en utilisant Apache Spark (Scala/Python) dans Azure Databricks\"),\n",
    "    (\"Accompagnement du Product Owner\",\n",
    "     \"Impl√©menter des flux de donn√©es streaming et batch via Databricks Streaming et Apache Kafka\"),\n",
    "    (\"√âlaboration de reporting mensuel\",\n",
    "     \"Documenter les solutions d√©velopp√©es selon les normes internes\"),\n",
    "    (\"√âcriture de requ√™tes SQL pour KPIs marketing\",\n",
    "     \"Contribuer √† l‚Äô√©laboration des principes d‚Äôarchitecture data et de gouvernance des donn√©es\"),\n",
    "]\n",
    "\n",
    "# Pr√©paration des exemples\n",
    "train_examples = [\n",
    "    InputExample(texts=[t1, t2], label=1.0) for t1, t2 in positive_pairs\n",
    "] + [\n",
    "    InputExample(texts=[t1, t2], label=0.0) for t1, t2 in negative_pairs\n",
    "]\n",
    "\n",
    "# Improved training setup\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)  # Increased from 4\n",
    "\n",
    "# Use ContrastiveLoss instead of CosineSimilarityLoss for binary labels\n",
    "# ContrastiveLoss is designed for positive/negative pairs with margin-based learning\n",
    "train_loss = losses.ContrastiveLoss(\n",
    "    model,\n",
    "    distance_metric=losses.SiameseDistanceMetric.COSINE_DISTANCE,\n",
    "    margin=0.5  # Margin between positive and negative pairs\n",
    ")\n",
    "\n",
    "print(f\"Training with {len(train_examples)} examples\")\n",
    "print(f\"Positive pairs: {len(positive_pairs)}, Negative pairs: {len(negative_pairs)}\")\n",
    "print(f\"Using ContrastiveLoss with margin=0.5\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=5,  # Increased from 3\n",
    "    warmup_steps=100,  # Increased from 10\n",
    "    optimizer_params={'lr': 2e-5},  # Explicit learning rate\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Sauvegarde du mod√®le\n",
    "model.save(\"modelfinetuned2\")\n",
    "print(\"‚úÖ Model saved to modelfinetuned2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'modelfinetuned2' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8477262258529663\n",
      "0.4947778582572937\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "#model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "#model = SentenceTransformer('modelfinetuned1')\n",
    "model = SentenceTransformer(\"modelfinetuned2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "\n",
    "    embeddings1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(text2, convert_to_tensor=True)\n",
    "\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores.item()\n",
    "\n",
    "\n",
    "text1 = \"Created various Customized and interactive Reports and Dashboards in Power BI.\"\n",
    "text2 = \"developement de dashboard sur Power BI\"\n",
    "text3 = \"Mettre en place un flux de donn√©es depuis un ERP vers une database Snowflake\"\n",
    "text4 = \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps (CI/CD, versioning, rollback).\"\n",
    "text5 = \"impl√©menter un pipeline d‚Äôint√©gration de donn√©es entre un syst√®me ERP et une base de donn√©es Snowflake\"\n",
    "#compute_similarity(text3, text1)\n",
    "#compute_similarity(text3, text2)\n",
    "print(compute_similarity(text1, text2))\n",
    "print(compute_similarity(text1, text5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3277907371520996\n",
      "-0.018768634647130966\n",
      "0.7804136276245117\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "\n",
    "    embeddings1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(text2, convert_to_tensor=True)\n",
    "\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores.item()\n",
    "\n",
    "\n",
    "text1 = \"Created various Customized and interactive Reports and Dashboards in Power BI.\"\n",
    "text2 = \"developement de dashboard sur Power BI\"\n",
    "text3 = \"potatoes are good\"\n",
    "text4 = \"Mettre en place un flux de donn√©es depuis un ERP vers une database Snowflake\"\n",
    "text5 = \"Automatiser les d√©ploiements et les tests des pipelines via Azure DevOps (CI/CD, versioning, rollback).\"\n",
    "text6 = \"impl√©menter un pipeline d‚Äôint√©gration de donn√©es entre un syst√®me ERP et une base de donn√©es Snowflake\"\n",
    "#compute_similarity(text3, text1)\n",
    "#compute_similarity(text3, text2)\n",
    "print(compute_similarity(text1, text6))\n",
    "print(compute_similarity(text1, text3))\n",
    "print(compute_similarity(text1, text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now need to do the same but for skills. \n",
    "\n",
    "embeddings for skills in same domain : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding the mission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmission = pd.read_csv(\"skills-finder-hackathon-hec-x-sbi/HCK_HEC_XP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmission = dfmission.drop_duplicates(subset=['USER_ID', 'MISSION_DSC'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'modelfinetuned2' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"modelfinetuned2\")\n",
    "consultant_embeddings = model.encode(dfmission['MISSION_DSC'].tolist(), convert_to_tensor=True, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
